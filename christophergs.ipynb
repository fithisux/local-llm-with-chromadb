{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52fc5a45-b7bd-4ef0-b4a2-1bd89bdef6a9",
   "metadata": {
    "id": "52fc5a45-b7bd-4ef0-b4a2-1bd89bdef6a9"
   },
   "source": [
    "From [Christorpher GS Blog](https://christophergs.com/blog/ai-engineering-retrieval-augmented-generation-rag-llama-index)\n",
    "\n",
    "Definitely needs a GPU in Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe852d2b-8a02-40cb-8ff2-e6efb2611b0b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 218577,
     "status": "ok",
     "timestamp": 1709195644741,
     "user": {
      "displayName": "Agile Developer",
      "userId": "11373447133358713473"
     },
     "user_tz": -120
    },
    "id": "fe852d2b-8a02-40cb-8ff2-e6efb2611b0b",
    "outputId": "90a56e7b-12c6-494e-805a-8bc3427c1e03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (2023.6.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (4.66.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (4.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (23.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (2024.2.2)\n",
      "Consider using `hf_transfer` for faster downloads. This solution comes with some limitations. See https://huggingface.co/docs/huggingface_hub/hf_transfer for more details.\n",
      "downloading https://huggingface.co/TheBloke/Mixtral-8x7B-Instruct-v0.1-GGUF/resolve/main/mixtral-8x7b-instruct-v0.1.Q4_K_M.gguf to /root/.cache/huggingface/hub/tmp1veqz8cg\n",
      "mixtral-8x7b-instruct-v0.1.Q4_K_M.gguf: 100% 26.4G/26.4G [03:32<00:00, 124MB/s]\n",
      "./mixtral-8x7b-instruct-v0.1.Q4_K_M.gguf\n"
     ]
    }
   ],
   "source": [
    "# get model\n",
    "\n",
    "# download the Trial by Sorcery file from here https://manybooks.net/titles/trial-by-sorcery\n",
    "\n",
    "# get the model\n",
    "\n",
    "!pip3 install huggingface-hub\n",
    "!huggingface-cli download TheBloke/Mixtral-8x7B-Instruct-v0.1-GGUF mixtral-8x7b-instruct-v0.1.Q4_K_M.gguf --local-dir . --local-dir-use-symlinks False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "RsOBN0MdQKVS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 302168,
     "status": "ok",
     "timestamp": 1709196012198,
     "user": {
      "displayName": "Agile Developer",
      "userId": "11373447133358713473"
     },
     "user_tz": -120
    },
    "id": "RsOBN0MdQKVS",
    "outputId": "be4ad9f5-7edd-4f26-c823-aa364638b976"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama_index\n",
      "  Downloading llama_index-0.10.14-py3-none-any.whl (5.6 kB)\n",
      "Collecting llama-index-agent-openai<0.2.0,>=0.1.4 (from llama_index)\n",
      "  Downloading llama_index_agent_openai-0.1.5-py3-none-any.whl (12 kB)\n",
      "Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama_index)\n",
      "  Downloading llama_index_cli-0.1.6-py3-none-any.whl (25 kB)\n",
      "Collecting llama-index-core<0.11.0,>=0.10.14 (from llama_index)\n",
      "  Downloading llama_index_core-0.10.14-py3-none-any.whl (15.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama_index)\n",
      "  Downloading llama_index_embeddings_openai-0.1.6-py3-none-any.whl (6.0 kB)\n",
      "Collecting llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 (from llama_index)\n",
      "  Downloading llama_index_indices_managed_llama_cloud-0.1.3-py3-none-any.whl (6.6 kB)\n",
      "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama_index)\n",
      "  Downloading llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting llama-index-llms-openai<0.2.0,>=0.1.5 (from llama_index)\n",
      "  Downloading llama_index_llms_openai-0.1.6-py3-none-any.whl (9.4 kB)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama_index)\n",
      "  Downloading llama_index_multi_modal_llms_openai-0.1.4-py3-none-any.whl (5.8 kB)\n",
      "Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama_index)\n",
      "  Downloading llama_index_program_openai-0.1.4-py3-none-any.whl (4.1 kB)\n",
      "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama_index)\n",
      "  Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n",
      "Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama_index)\n",
      "  Downloading llama_index_readers_file-0.1.6-py3-none-any.whl (34 kB)\n",
      "Collecting llama-index-readers-llama-parse<0.2.0,>=0.1.2 (from llama_index)\n",
      "  Downloading llama_index_readers_llama_parse-0.1.3-py3-none-any.whl (2.5 kB)\n",
      "Collecting llama-index-vector-stores-chroma<0.2.0,>=0.1.1 (from llama-index-cli<0.2.0,>=0.1.2->llama_index)\n",
      "  Downloading llama_index_vector_stores_chroma-0.1.5-py3-none-any.whl (4.7 kB)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.14->llama_index) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.14->llama_index) (2.0.27)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.14->llama_index) (3.9.3)\n",
      "Collecting dataclasses-json (from llama-index-core<0.11.0,>=0.10.14->llama_index)\n",
      "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.11.0,>=0.10.14->llama_index)\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.11.0,>=0.10.14->llama_index)\n",
      "  Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.14->llama_index) (2023.6.0)\n",
      "Collecting httpx (from llama-index-core<0.11.0,>=0.10.14->llama_index)\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting llamaindex-py-client<0.2.0,>=0.1.13 (from llama-index-core<0.11.0,>=0.10.14->llama_index)\n",
      "  Downloading llamaindex_py_client-0.1.13-py3-none-any.whl (107 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.14->llama_index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.14->llama_index) (3.2.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.14->llama_index) (3.8.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.14->llama_index) (1.25.2)\n",
      "Collecting openai>=1.1.0 (from llama-index-core<0.11.0,>=0.10.14->llama_index)\n",
      "  Downloading openai-1.13.3-py3-none-any.whl (227 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.4/227.4 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.14->llama_index) (1.5.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.14->llama_index) (9.4.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.14->llama_index) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.14->llama_index) (8.2.3)\n",
      "Collecting tiktoken>=0.3.3 (from llama-index-core<0.11.0,>=0.10.14->llama_index)\n",
      "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.14->llama_index) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.14->llama_index) (4.9.0)\n",
      "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.11.0,>=0.10.14->llama_index)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama_index) (4.12.3)\n",
      "Collecting bs4<0.0.3,>=0.0.2 (from llama-index-readers-file<0.2.0,>=0.1.4->llama_index)\n",
      "  Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
      "Collecting pymupdf<2.0.0,>=1.23.21 (from llama-index-readers-file<0.2.0,>=0.1.4->llama_index)\n",
      "  Downloading PyMuPDF-1.23.25-cp310-none-manylinux2014_x86_64.whl (4.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.2.0,>=0.1.4->llama_index)\n",
      "  Downloading pypdf-4.0.2-py3-none-any.whl (283 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.0/284.0 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting llama-parse<0.4.0,>=0.3.3 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index)\n",
      "  Downloading llama_parse-0.3.5-py3-none-any.whl (7.7 kB)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.14->llama_index) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.14->llama_index) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.14->llama_index) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.14->llama_index) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.14->llama_index) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.14->llama_index) (4.0.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama_index) (2.5)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.9.3->llama-index-core<0.11.0,>=0.10.14->llama_index) (1.14.1)\n",
      "Collecting chromadb<0.5.0,>=0.4.22 (from llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index)\n",
      "  Downloading chromadb-0.4.24-py3-none-any.whl (525 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m525.5/525.5 kB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting onnxruntime<2.0.0,>=1.17.0 (from llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index)\n",
      "  Downloading onnxruntime-1.17.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tokenizers<0.16.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index) (0.15.2)\n",
      "Requirement already satisfied: pydantic>=1.10 in /usr/local/lib/python3.10/dist-packages (from llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.14->llama_index) (2.6.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.14->llama_index) (3.7.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.14->llama_index) (2024.2.2)\n",
      "Collecting httpcore==1.* (from httpx->llama-index-core<0.11.0,>=0.10.14->llama_index)\n",
      "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.14->llama_index) (3.6)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.14->llama_index) (1.3.0)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.14->llama_index)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.14->llama_index) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.14->llama_index) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.14->llama_index) (2023.12.25)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.14->llama_index) (1.7.0)\n",
      "Collecting PyMuPDFb==1.23.22 (from pymupdf<2.0.0,>=1.23.21->llama-index-readers-file<0.2.0,>=0.1.4->llama_index)\n",
      "  Downloading PyMuPDFb-1.23.22-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (30.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.6/30.6 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.14->llama_index) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.14->llama_index) (2.0.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.14->llama_index) (3.0.3)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.14->llama_index)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.11.0,>=0.10.14->llama_index)\n",
      "  Downloading marshmallow-3.21.0-py3-none-any.whl (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.14->llama_index) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.14->llama_index) (2023.4)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.14->llama_index) (1.2.0)\n",
      "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index) (1.0.3)\n",
      "Collecting chroma-hnswlib==0.7.3 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index)\n",
      "  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m99.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fastapi>=0.95.2 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index)\n",
      "  Downloading fastapi-0.110.0-py3-none-any.whl (92 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index)\n",
      "  Downloading uvicorn-0.27.1-py3-none-any.whl (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting posthog>=2.4.0 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index)\n",
      "  Downloading posthog-3.4.2-py2.py3-none-any.whl (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pulsar-client>=3.1.0 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index)\n",
      "  Downloading pulsar_client-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting opentelemetry-api>=1.2.0 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index)\n",
      "  Downloading opentelemetry_api-1.23.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.23.0-py3-none-any.whl (18 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index)\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.44b0-py3-none-any.whl (11 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index)\n",
      "  Downloading opentelemetry_sdk-1.23.0-py3-none-any.whl (105 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.7/105.7 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pypika>=0.48.9 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting overrides>=7.3.1 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index)\n",
      "  Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index) (6.1.1)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index) (1.60.1)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index)\n",
      "  Downloading bcrypt-4.1.2-cp39-abi3-manylinux_2_28_x86_64.whl (698 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index) (0.9.0)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index)\n",
      "  Downloading kubernetes-29.0.0-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m101.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting mmh3>=4.0.1 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index)\n",
      "  Downloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting orjson>=3.9.12 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index)\n",
      "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.14->llama_index) (23.2)\n",
      "Collecting coloredlogs (from onnxruntime<2.0.0,>=1.17.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2.0.0,>=1.17.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index) (23.5.26)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2.0.0,>=1.17.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index) (3.20.3)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2.0.0,>=1.17.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index) (1.12)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.14->llama_index) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.14->llama_index) (2.16.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->llama-index-core<0.11.0,>=0.10.14->llama_index) (1.16.0)\n",
      "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers<0.16.0,>=0.15.1->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index) (0.20.3)\n",
      "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index) (1.0.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index) (2.0.1)\n",
      "Collecting starlette<0.37.0,>=0.36.3 (from fastapi>=0.95.2->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index)\n",
      "  Downloading starlette-0.36.3-py3-none-any.whl (71 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers<0.16.0,>=0.15.1->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index) (3.13.1)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index) (2.27.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index) (1.7.0)\n",
      "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index) (1.3.1)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index) (3.2.2)\n",
      "Collecting importlib-metadata<7.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index)\n",
      "  Downloading importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index) (1.62.0)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.23.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.23.0-py3-none-any.whl (17 kB)\n",
      "Collecting opentelemetry-proto==1.23.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index)\n",
      "  Downloading opentelemetry_proto-1.23.0-py3-none-any.whl (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting opentelemetry-instrumentation-asgi==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index)\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.44b0-py3-none-any.whl (14 kB)\n",
      "Collecting opentelemetry-instrumentation==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index)\n",
      "  Downloading opentelemetry_instrumentation-0.44b0-py3-none-any.whl (28 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index)\n",
      "  Downloading opentelemetry_semantic_conventions-0.44b0-py3-none-any.whl (36 kB)\n",
      "Collecting opentelemetry-util-http==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index)\n",
      "  Downloading opentelemetry_util_http-0.44b0-py3-none-any.whl (6.9 kB)\n",
      "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index) (67.7.2)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index)\n",
      "  Downloading asgiref-3.7.2-py3-none-any.whl (24 kB)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index)\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index)\n",
      "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index)\n",
      "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index)\n",
      "  Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index)\n",
      "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<2.0.0,>=1.17.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime<2.0.0,>=1.17.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index) (1.3.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index) (4.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index) (3.17.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama_index) (0.5.1)\n",
      "Building wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53723 sha256=9764678c0921c996040022a4fc7eee9b493a3ac5b64aaec37aa385cdd190b6fb\n",
      "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
      "Successfully built pypika\n",
      "Installing collected packages: pypika, monotonic, mmh3, dirtyjson, websockets, uvloop, python-dotenv, pypdf, PyMuPDFb, pulsar-client, overrides, orjson, opentelemetry-util-http, opentelemetry-semantic-conventions, opentelemetry-proto, mypy-extensions, marshmallow, importlib-metadata, humanfriendly, httptools, h11, deprecated, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, uvicorn, typing-inspect, tiktoken, starlette, pymupdf, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, httpcore, coloredlogs, bs4, opentelemetry-sdk, opentelemetry-instrumentation, onnxruntime, kubernetes, httpx, fastapi, dataclasses-json, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, openai, llamaindex-py-client, opentelemetry-instrumentation-fastapi, llama-index-legacy, llama-index-core, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, chromadb, llama-index-vector-stores-chroma, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-agent-openai, llama-index-program-openai, llama-index-cli, llama-index-question-gen-openai, llama_index\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 7.0.1\n",
      "    Uninstalling importlib-metadata-7.0.1:\n",
      "      Successfully uninstalled importlib-metadata-7.0.1\n",
      "Successfully installed PyMuPDFb-1.23.22 asgiref-3.7.2 backoff-2.2.1 bcrypt-4.1.2 bs4-0.0.2 chroma-hnswlib-0.7.3 chromadb-0.4.24 coloredlogs-15.0.1 dataclasses-json-0.6.4 deprecated-1.2.14 dirtyjson-1.0.8 fastapi-0.110.0 h11-0.14.0 httpcore-1.0.4 httptools-0.6.1 httpx-0.27.0 humanfriendly-10.0 importlib-metadata-6.11.0 kubernetes-29.0.0 llama-index-agent-openai-0.1.5 llama-index-cli-0.1.6 llama-index-core-0.10.14 llama-index-embeddings-openai-0.1.6 llama-index-indices-managed-llama-cloud-0.1.3 llama-index-legacy-0.9.48 llama-index-llms-openai-0.1.6 llama-index-multi-modal-llms-openai-0.1.4 llama-index-program-openai-0.1.4 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.6 llama-index-readers-llama-parse-0.1.3 llama-index-vector-stores-chroma-0.1.5 llama-parse-0.3.5 llama_index-0.10.14 llamaindex-py-client-0.1.13 marshmallow-3.21.0 mmh3-4.1.0 monotonic-1.6 mypy-extensions-1.0.0 onnxruntime-1.17.1 openai-1.13.3 opentelemetry-api-1.23.0 opentelemetry-exporter-otlp-proto-common-1.23.0 opentelemetry-exporter-otlp-proto-grpc-1.23.0 opentelemetry-instrumentation-0.44b0 opentelemetry-instrumentation-asgi-0.44b0 opentelemetry-instrumentation-fastapi-0.44b0 opentelemetry-proto-1.23.0 opentelemetry-sdk-1.23.0 opentelemetry-semantic-conventions-0.44b0 opentelemetry-util-http-0.44b0 orjson-3.9.15 overrides-7.7.0 posthog-3.4.2 pulsar-client-3.4.0 pymupdf-1.23.25 pypdf-4.0.2 pypika-0.48.9 python-dotenv-1.0.1 starlette-0.36.3 tiktoken-0.6.0 typing-inspect-0.9.0 uvicorn-0.27.1 uvloop-0.19.0 watchfiles-0.21.0 websockets-12.0\n",
      "Collecting llama-index-embeddings-huggingface\n",
      "  Downloading llama_index_embeddings_huggingface-0.1.4-py3-none-any.whl (7.7 kB)\n",
      "Requirement already satisfied: huggingface-hub[inference]>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-embeddings-huggingface) (0.20.3)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-embeddings-huggingface) (0.10.14)\n",
      "Collecting torch<3.0.0,>=2.1.2 (from llama-index-embeddings-huggingface)\n",
      "  Downloading torch-2.2.1-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.37.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-embeddings-huggingface) (4.37.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2023.6.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.66.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (23.2)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.9.3)\n",
      "Requirement already satisfied: pydantic<3.0,>1.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.6.1)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2.0.27)\n",
      "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.6.4)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.0.8)\n",
      "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.27.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.13 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.1.13)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.2.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.8.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.25.2)\n",
      "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.13.3)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.5.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (9.4.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (8.2.3)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.6.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (1.12)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (3.1.3)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface)\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface)\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface)\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface)\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface)\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface)\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface)\n",
      "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface)\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting triton==2.2.0 (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface)\n",
      "  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.37.0->llama-index-embeddings-huggingface) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.37.0->llama-index-embeddings-huggingface) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.37.0->llama-index-embeddings-huggingface) (0.4.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.0.3)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.9.3->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.14.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.7.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.0.4)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.6)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.14.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.3.2)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.7.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0,>1.1->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0,>1.1->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.16.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.0.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2023.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.16.0)\n",
      "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, llama-index-embeddings-huggingface\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.1.0\n",
      "    Uninstalling triton-2.1.0:\n",
      "      Successfully uninstalled triton-2.1.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.1.0+cu121\n",
      "    Uninstalling torch-2.1.0+cu121:\n",
      "      Successfully uninstalled torch-2.1.0+cu121\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.1.0+cu121 requires torch==2.1.0, but you have torch 2.2.1 which is incompatible.\n",
      "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.2.1 which is incompatible.\n",
      "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.2.1 which is incompatible.\n",
      "torchvision 0.16.0+cu121 requires torch==2.1.0, but you have torch 2.2.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed llama-index-embeddings-huggingface-0.1.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.3.101 nvidia-nvtx-cu12-12.1.105 torch-2.2.1 triton-2.2.0\n",
      "Collecting llama-index-llms-llama-cpp\n",
      "  Downloading llama_index_llms_llama_cpp-0.1.3-py3-none-any.whl (5.1 kB)\n",
      "Collecting llama-cpp-python<0.3.0,>=0.2.32 (from llama-index-llms-llama-cpp)\n",
      "  Downloading llama_cpp_python-0.2.53.tar.gz (36.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.8/36.8 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-llama-cpp) (0.10.14)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python<0.3.0,>=0.2.32->llama-index-llms-llama-cpp) (4.9.0)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python<0.3.0,>=0.2.32->llama-index-llms-llama-cpp) (1.25.2)\n",
      "Collecting diskcache>=5.6.1 (from llama-cpp-python<0.3.0,>=0.2.32->llama-index-llms-llama-cpp)\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python<0.3.0,>=0.2.32->llama-index-llms-llama-cpp) (3.1.3)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (2.0.27)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (0.6.4)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (2023.6.0)\n",
      "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (0.27.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.13 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (0.1.13)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (3.2.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (3.8.1)\n",
      "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.13.3)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.5.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (9.4.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (8.2.3)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (0.6.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (4.66.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (0.9.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (4.0.3)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.9.3->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.14.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.3->llama-cpp-python<0.3.0,>=0.2.32->llama-index-llms-llama-cpp) (2.1.5)\n",
      "Requirement already satisfied: pydantic>=1.10 in /usr/local/lib/python3.10/dist-packages (from llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (2.6.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (3.7.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.0.4)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (3.6)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (0.14.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (2023.12.25)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (2.0.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (3.21.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (2023.4)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.2.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (23.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (2.16.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.16.0)\n",
      "Building wheels for collected packages: llama-cpp-python\n",
      "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.53-cp310-cp310-manylinux_2_35_x86_64.whl size=2751942 sha256=6d4e0908c484e0e66ab758c5ea52c602f92529cee5d30b20c0563b69a37687b3\n",
      "  Stored in directory: /root/.cache/pip/wheels/56/94/10/5407d0fd0a979d77bef8df3d298af7d1d60193b6b759ad217f\n",
      "Successfully built llama-cpp-python\n",
      "Installing collected packages: diskcache, llama-cpp-python, llama-index-llms-llama-cpp\n",
      "Successfully installed diskcache-5.6.3 llama-cpp-python-0.2.53 llama-index-llms-llama-cpp-0.1.3\n"
     ]
    }
   ],
   "source": [
    "%pip install llama_index\n",
    "%pip install llama-index-embeddings-huggingface\n",
    "%pip install llama-index-llms-llama-cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0383c557-69d7-4988-a06a-e6516f3760e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 26 key-value pairs and 995 tensors from ./mixtral-8x7b-instruct-v0.1.Q4_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = mistralai_mixtral-8x7b-instruct-v0.1\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:                         llama.expert_count u32              = 8\n",
      "llama_model_loader: - kv  10:                    llama.expert_used_count u32              = 2\n",
      "llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  12:                       llama.rope.freq_base f32              = 1000000.000000\n",
      "llama_model_loader: - kv  13:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  14:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  15:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  16:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  17:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  18:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  19:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  20:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  21:            tokenizer.ggml.padding_token_id u32              = 0\n",
      "llama_model_loader: - kv  22:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  23:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  24:                    tokenizer.chat_template str              = {{ bos_token }}{% for message in mess...\n",
      "llama_model_loader: - kv  25:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type  f16:   32 tensors\n",
      "llama_model_loader: - type q8_0:   64 tensors\n",
      "llama_model_loader: - type q4_K:  833 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 8\n",
      "llm_load_print_meta: n_expert_used    = 2\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 1000000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 46.70 B\n",
      "llm_load_print_meta: model size       = 24.62 GiB (4.53 BPW) \n",
      "llm_load_print_meta: general.name     = mistralai_mixtral-8x7b-instruct-v0.1\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.38 MiB\n",
      "llm_load_tensors:        CPU buffer size = 25215.87 MiB\n",
      "....................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 32000\n",
      "llama_new_context_with_model: freq_base  = 1000000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =  4000.00 MiB\n",
      "llama_new_context_with_model: KV self size  = 4000.00 MiB, K (f16): 2000.00 MiB, V (f16): 2000.00 MiB\n",
      "llama_new_context_with_model:        CPU input buffer size   =    71.63 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =  2052.03 MiB\n",
      "llama_new_context_with_model: graph splits (measure): 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | \n",
      "Model metadata: {'tokenizer.chat_template': \"{{ bos_token }}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if message['role'] == 'user' %}{{ '[INST] ' + message['content'] + ' [/INST]' }}{% elif message['role'] == 'assistant' %}{{ message['content'] + eos_token}}{% else %}{{ raise_exception('Only user and assistant roles are supported!') }}{% endif %}{% endfor %}\", 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.ggml.padding_token_id': '0', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '15', 'general.architecture': 'llama', 'llama.rope.freq_base': '1000000.000000', 'tokenizer.ggml.add_bos_token': 'true', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.bos_token_id': '1', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8', 'llama.expert_count': '8', 'llama.context_length': '32768', 'general.name': 'mistralai_mixtral-8x7b-instruct-v0.1', 'llama.expert_used_count': '2'}\n",
      "Using chat template: {{ bos_token }}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if message['role'] == 'user' %}{{ '[INST] ' + message['content'] + ' [/INST]' }}{% elif message['role'] == 'assistant' %}{{ message['content'] + eos_token}}{% else %}{{ raise_exception('Only user and assistant roles are supported!') }}{% endif %}{% endfor %}\n",
      "Using chat eos_token: \n",
      "Using chat bos_token: \n"
     ]
    }
   ],
   "source": [
    "# cpu based\n",
    "from llama_index.llms.llama_cpp import LlamaCPP\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"10\"\n",
    "\n",
    "llm = LlamaCPP(\n",
    "    model_path=\"./mixtral-8x7b-instruct-v0.1.Q4_K_M.gguf\",  # https://huggingface.co/TheBloke/Mixtral-8x7B-Instruct-v0.1-GGUF\n",
    "    context_window=32000,\n",
    "    max_new_tokens=1024,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "embedding_model = HuggingFaceEmbedding(model_name=\"WhereIsAI/UAE-Large-V1\")  # https://huggingface.co/WhereIsAI/UAE-Large-V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "305fb7ad-2745-4a2d-bade-839283f1c8fb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "df5c051dafd64e80865173434a61ffc8",
      "291a6354dc6e4698865e3d86c5ee1bb1",
      "85c9afe57c22490c98b49ddff86b8c2c",
      "d87b40175e364504aedf2e38a594fbae",
      "eb3a2814a8f4480480dd1c8892b4a72d",
      "2d00f832a6ae4c4288a03a7e61bc2f49",
      "423845aaad2d48b7b856fc60d8fc6f4f",
      "c51356f765d44349b5ba0c8bf09428f8",
      "5d7edaae86334f7d991de13d5b42d9a9",
      "50d2c55c2fb64a7e9ae727af6e2bae61",
      "502040ae722842d29c64fdf5756eb8cb",
      "0dfff2dfb6b542e4a200675937fff40e",
      "53c12114c0c949d6b669470ad7f127ed",
      "19d51f7d861f4b669ff8d955b48e45e1",
      "d331b53eaaf542a4ba7838c903b5d747",
      "ab6adf2409224f9bb6d6c5014a904207",
      "e344c647c7634e57b9ea3d80d3714f81",
      "61b466859383483ab406fce21056538c",
      "941b79c340d241d5a7323f7161c09272",
      "c5eca3d8e25c42898e9108462261b067",
      "0198d7b8d71e40389e77b23a060def04",
      "f65488d28f1d4499a19aa715a6807bfd",
      "4b8e1ccd5af1469fad3fa2f17b1fbb6e",
      "1e63d24a59b04ba1a7db63a613e7a99e",
      "9b1f3fcf64d4424b93dab8e108df5786",
      "20977fa7019d47f6ab4e37d037999b76",
      "c5a3731cc0774bcbbcc6063425146d0e",
      "cc6a49cdbea44b2ba7d2c15724828d31",
      "32990c042d744ad3afae3e03eac3fe1f",
      "cdebc24318424786894d1aafff286821",
      "ea00bc805dee49b5afe998d680bf4b4e",
      "2eaba381f8b946adb9b5c89bcae78685",
      "4fa422a6c52a48be88f810caba43fca1",
      "bb3ca13726c2495aa3d3b3f7480b2a37",
      "610c6698d8ba41f5915f5fb8f940cc14",
      "2db16ed3278c4bfe8acf9202768de6b1",
      "319d6139ec7d4864a18b60bef75032aa",
      "0908a20f70514e55bbf234dbfe459479",
      "415b7764079a4f91a95d0d166487bc42",
      "cdc0c7eeb9cd4efa8a106c73bdda9cee",
      "89dfd97749224ed3a58e8f4d6bdf5158",
      "1e2bf2cba46f4c49b1136a8bab67df0a",
      "b4aa2d88328948b882e7b17764042f69",
      "dff9671556f149ba9f9a9f0425e44b02",
      "7eb52167968e4550b7911d62e940d7a7",
      "a9e02338e37a403d89c7e454181b5d24",
      "394193e2ea6e47bd95c15c72cfb01b11",
      "b151f46987594085b7013dde99353200",
      "0961894699e34a2b8f2007e0673ed050",
      "e59e1197b6ab4b7db539a2e140bf0140",
      "9880bec0ae7e48499c6789b024e01577",
      "852773c444a84b0cb7bf793c9ec5be8f",
      "7b12d5154319457f858cdc54d09d4fe6",
      "0e4d11dbcb5243059796de69fa05b278",
      "c1b908b2648d458ab6a002a52681562d",
      "86c340ce56fd4778b8baba861144f72e",
      "f88c414bbe9d45c889b45f1425eb033b",
      "568ebe15c3914a25a5810d1b61024560",
      "c7d73f2a4fc24f0cacf444fbca6e8167",
      "079325b4c6c643558d583e5a1eec89b9",
      "a0410383f3e84975af0126e862552c16",
      "ac9730efa73d4f319f163ea4db9cb832",
      "7ac20c42ab39447f881ba5cc364491d1",
      "d8668140890b446c8cb2ed00bfd758f0",
      "93978c30008b43678baa672ad1a804cf",
      "72da250867914ebb8d84c35f9cf8d9e2",
      "59776c188ba845598e081a863cab2275",
      "41808496e82a496b8a8bf897e753ee34",
      "0003af9453b9461a966296196a65c48d",
      "b748bcb289b54f9f8b32be94b66e2242",
      "ab53ccdc938c41fe9436f0221b2a3c0a",
      "ca9eb1ba34064f358b5c9dac35ad96d5",
      "3f70af433ed14f689a6328744342b3f5",
      "6b1bb5f074064eed9508e76ed7aa85c1",
      "6d9898e60250427da3a2876ae1f2f754",
      "ca23ad2fd52a4298bb552c868d94f491",
      "57b85f6768b24faba97e6516d0161024"
     ]
    },
    "executionInfo": {
     "elapsed": 151116,
     "status": "ok",
     "timestamp": 1709196332119,
     "user": {
      "displayName": "Agile Developer",
      "userId": "11373447133358713473"
     },
     "user_tz": -120
    },
    "id": "305fb7ad-2745-4a2d-bade-839283f1c8fb",
    "outputId": "32ceb579-aea1-4d13-b955-9f8f444fd07c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df5c051dafd64e80865173434a61ffc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 26 key-value pairs and 995 tensors from ./mixtral-8x7b-instruct-v0.1.Q4_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = mistralai_mixtral-8x7b-instruct-v0.1\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:                         llama.expert_count u32              = 8\n",
      "llama_model_loader: - kv  10:                    llama.expert_used_count u32              = 2\n",
      "llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  12:                       llama.rope.freq_base f32              = 1000000.000000\n",
      "llama_model_loader: - kv  13:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  14:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  15:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  16:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  17:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  18:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  19:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  20:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  21:            tokenizer.ggml.padding_token_id u32              = 0\n",
      "llama_model_loader: - kv  22:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  23:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  24:                    tokenizer.chat_template str              = {{ bos_token }}{% for message in mess...\n",
      "llama_model_loader: - kv  25:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type  f16:   32 tensors\n",
      "llama_model_loader: - type q8_0:   64 tensors\n",
      "llama_model_loader: - type q4_K:  833 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 8\n",
      "llm_load_print_meta: n_expert_used    = 2\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 1000000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 46.70 B\n",
      "llm_load_print_meta: model size       = 24.62 GiB (4.53 BPW) \n",
      "llm_load_print_meta: general.name     = mistralai_mixtral-8x7b-instruct-v0.1\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.38 MiB\n",
      "llm_load_tensors:        CPU buffer size = 25215.87 MiB\n",
      "....................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 32000\n",
      "llama_new_context_with_model: freq_base  = 1000000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =  4000.00 MiB\n",
      "llama_new_context_with_model: KV self size  = 4000.00 MiB, K (f16): 2000.00 MiB, V (f16): 2000.00 MiB\n",
      "llama_new_context_with_model:        CPU input buffer size   =    71.75 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =  2052.03 MiB\n",
      "llama_new_context_with_model: graph splits (measure): 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | \n",
      "Model metadata: {'tokenizer.chat_template': \"{{ bos_token }}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if message['role'] == 'user' %}{{ '[INST] ' + message['content'] + ' [/INST]' }}{% elif message['role'] == 'assistant' %}{{ message['content'] + eos_token}}{% else %}{{ raise_exception('Only user and assistant roles are supported!') }}{% endif %}{% endfor %}\", 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.ggml.padding_token_id': '0', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '15', 'general.architecture': 'llama', 'llama.rope.freq_base': '1000000.000000', 'tokenizer.ggml.add_bos_token': 'true', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.bos_token_id': '1', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8', 'llama.expert_count': '8', 'llama.context_length': '32768', 'general.name': 'mistralai_mixtral-8x7b-instruct-v0.1', 'llama.expert_used_count': '2'}\n",
      "Guessed chat format: mistral-instruct\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dfff2dfb6b542e4a200675937fff40e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/733 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b8e1ccd5af1469fad3fa2f17b1fbb6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb3ca13726c2495aa3d3b3f7480b2a37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.24k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eb52167968e4550b7911d62e940d7a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86c340ce56fd4778b8baba861144f72e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59776c188ba845598e081a863cab2275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # gpu based\n",
    "# from llama_index.llms.llama_cpp import LlamaCPP\n",
    "# from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "# llm = LlamaCPP(\n",
    "#     model_path=\"./mixtral-8x7b-instruct-v0.1.Q4_K_M.gguf\",  # https://huggingface.co/TheBloke/Mixtral-8x7B-Instruct-v0.1-GGUF\n",
    "#     context_window=32000,\n",
    "#     max_new_tokens=1024,\n",
    "#     model_kwargs={'n_gpu_layers': 1},\n",
    "#     verbose=True\n",
    "# )\n",
    "\n",
    "# embedding_model = HuggingFaceEmbedding(model_name=\"WhereIsAI/UAE-Large-V1\")  # https://huggingface.co/WhereIsAI/UAE-Large-V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bacda66-39d8-4217-a27b-1274f667f29e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "b0261842d4db444ab7e3da62ff57e63f",
      "337cc33084e44a83a5ff6ecff24b773a",
      "97fc2dd9aa4c473f8f24681b09fdb14d",
      "bea91842bf04485d8cd5fb966e576e78",
      "c2b138dadc284228bac0ac57efeb1126",
      "76066fc64a194d288a222fef218d1df1",
      "72c30a2b48fe4b4589a14b8f03a766f9",
      "ee5ca0ccdae844499527ee6621b8b674",
      "a4cf1767ced148e19230acddc1ee0111",
      "6dfead868430481185af3dbcc5a6e7bd",
      "ff368e09220e4b1794d85f99e09839af",
      "2e66c38f5e404ce4bbf2a0a6edba89a3",
      "036854173d994890ac1a9e1e3ef8ab3b",
      "1b0f31be2647435fbe4a464ff76f62d1",
      "19c0f5a7175e4891b93752da31961c0e",
      "d69be2c59406490e819c707500c0b9cb",
      "b848919dae244b4998ce23575f698ca0",
      "4c214d64753d4a0ab6bfd0999b7ef8e9",
      "e8eacde2202e43008bf8b35262b32e1f",
      "3e0a63cf422a432b93dc7af1ff7cf85b",
      "4c5ea5aab14a4721b1627d497a94148a",
      "a0c881300a4746e4aaa6efd795cb8e66",
      "588df6baf97f4d89b47e384935544680",
      "54cd52f55628482eb6fd8acdfe08b788",
      "7d79784221834c1e815afe3121203674",
      "d1a8527e05914c95917e8507900a64ca",
      "200eb5111a5b4fa8b604b32a14f37e0e",
      "b7439fa380a3479485a72f22d6a7b074",
      "90e360057d1b4f97bd0226fa0a0c6883",
      "e2eaa932d419460da2c3ef4372e11908",
      "c48ad5335e6949f1b913b178f25ae0d0",
      "d59b58dc490f480493238b0badd9f22d",
      "2e726638713b4af9abaf65bd35376863",
      "ccc1f56170bf457cab2d20bb58377bc4",
      "1b9bb6444205426d9f2c1e3084d47c03",
      "1f42c6913eab4a618278ae877b21fd14",
      "6cf9d2700a5041bba56802ac4f6ec72e",
      "eb06dd2d906d46cc890a87555cfe334d",
      "48e9035160644613bf4ee8a6c22d4743",
      "97ae325b7caa47bcb3c4784dbfb73cf9",
      "e70f92cdd188498ebff8f320ac112998",
      "b1730ee391ec4ef9a3dd9e2e9876417a",
      "7af4423428384ebea388f88695fd5d50",
      "a521df36522d4b549596bbc69a015221"
     ]
    },
    "executionInfo": {
     "elapsed": 983,
     "status": "ok",
     "timestamp": 1709196428564,
     "user": {
      "displayName": "Agile Developer",
      "userId": "11373447133358713473"
     },
     "user_tz": -120
    },
    "id": "3bacda66-39d8-4217-a27b-1274f667f29e",
    "outputId": "7956ee66-4ff9-42a9-d22f-9cff926ebe24"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mixtral-8x7B-Instruct-v0.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46b63b6b-efd2-4388-833e-316c23cbe6a6",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1709196431700,
     "user": {
      "displayName": "Agile Developer",
      "userId": "11373447133358713473"
     },
     "user_tz": -120
    },
    "id": "46b63b6b-efd2-4388-833e-316c23cbe6a6"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "from llama_index.core import set_global_handler\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "set_global_handler(\"simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d528b4a9-b1b6-43c3-8f3b-c148b9043985",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31126,
     "status": "ok",
     "timestamp": 1709196482025,
     "user": {
      "displayName": "Agile Developer",
      "userId": "11373447133358713473"
     },
     "user_tz": -120
    },
    "id": "d528b4a9-b1b6-43c3-8f3b-c148b9043985",
    "outputId": "ecaa014f-41a7-4f84-a379-aeb14d6c85c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:chromadb.auth.registry:Registering provider: token_config\n",
      "Registering provider: token_config\n",
      "DEBUG:chromadb.auth.registry:Registering provider: user_token_config\n",
      "Registering provider: user_token_config\n",
      "DEBUG:chromadb.auth.registry:Registering provider: token\n",
      "Registering provider: token\n",
      "DEBUG:chromadb.auth.registry:Registering provider: token\n",
      "Registering provider: token\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:7: DeprecationWarning: Call to deprecated function (or staticmethod) download_loader. (`download_loader()` is deprecated. Please install tool using pip install directly instead.)\n",
      "<timed exec>:12: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "DEBUG:chromadb.config:Starting component System\n",
      "Starting component System\n",
      "DEBUG:chromadb.config:Starting component Posthog\n",
      "Starting component Posthog\n",
      "DEBUG:chromadb.config:Starting component OpenTelemetryClient\n",
      "Starting component OpenTelemetryClient\n",
      "DEBUG:chromadb.config:Starting component SimpleAssignmentPolicy\n",
      "Starting component SimpleAssignmentPolicy\n",
      "DEBUG:chromadb.config:Starting component SqliteDB\n",
      "Starting component SqliteDB\n",
      "DEBUG:chromadb.config:Starting component QuotaEnforcer\n",
      "Starting component QuotaEnforcer\n",
      "DEBUG:chromadb.config:Starting component LocalSegmentManager\n",
      "Starting component LocalSegmentManager\n",
      "DEBUG:chromadb.config:Starting component SegmentAPI\n",
      "Starting component SegmentAPI\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: \n",
      "> Adding chunk: \n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Trial\n",
      "by\n",
      "Sorcery\n",
      "\t\n",
      "Dragon\tRiders\tof\tOsnen\tBook\t...\n",
      "> Adding chunk: Trial\n",
      "by\n",
      "Sorcery\n",
      "\t\n",
      "Dragon\tRiders\tof\tOsnen\tBook\t...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Trial\tby\tSorcery\t©\t2020\tby\tRichard\tFierce\n",
      "\t\n",
      "\t\n",
      "T...\n",
      "> Adding chunk: Trial\tby\tSorcery\t©\t2020\tby\tRichard\tFierce\n",
      "\t\n",
      "\t\n",
      "T...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: TABLE\tOF\tCONTENTS\n",
      "Chapter\t1\n",
      "Chapter\t2\n",
      "Chapter\t3...\n",
      "> Adding chunk: TABLE\tOF\tCONTENTS\n",
      "Chapter\t1\n",
      "Chapter\t2\n",
      "Chapter\t3...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 1\n",
      "\t\n",
      "I\tmarveled\tat\tthe\tvastness\tof\tthe\tCitadel.\n",
      "...\n",
      "> Adding chunk: 1\n",
      "\t\n",
      "I\tmarveled\tat\tthe\tvastness\tof\tthe\tCitadel.\n",
      "...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: least\ta\thundred\tpeople\twaiting\tto\tget\tinto\tthe\t...\n",
      "> Adding chunk: least\ta\thundred\tpeople\twaiting\tto\tget\tinto\tthe\t...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: I\tnodded\tat\thim,\tstill\tsmiling,\tand\twalked\tover...\n",
      "> Adding chunk: I\tnodded\tat\thim,\tstill\tsmiling,\tand\twalked\tover...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: giving\tme\ta\tdeath\tstare.\n",
      "“Did\tI\task\tfor\tyour\the...\n",
      "> Adding chunk: giving\tme\ta\tdeath\tstare.\n",
      "“Did\tI\task\tfor\tyour\the...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: “Don’t\tworry\tabout\tit,”\tI\tsaid.\n",
      "“No,\treally.\tI\t...\n",
      "> Adding chunk: “Don’t\tworry\tabout\tit,”\tI\tsaid.\n",
      "“No,\treally.\tI\t...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Girls\twere\todd\tcreatures.\n",
      "> Adding chunk: Girls\twere\todd\tcreatures.\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 2\n",
      "\t\n",
      "The\tentrance\tto\tthe\tCitadel\twas\tmuch\tmore\th...\n",
      "> Adding chunk: 2\n",
      "\t\n",
      "The\tentrance\tto\tthe\tCitadel\twas\tmuch\tmore\th...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: “I\thad\tno\tidea\tthey\twere\tso\tlarge,”\tI\tsaid.\n",
      "“Ye...\n",
      "> Adding chunk: “I\thad\tno\tidea\tthey\twere\tso\tlarge,”\tI\tsaid.\n",
      "“Ye...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: “Do\tI\tjust\tgo\tin?”\tI\tasked.\n",
      "The\tguard\tseemed\tco...\n",
      "> Adding chunk: “Do\tI\tjust\tgo\tin?”\tI\tasked.\n",
      "The\tguard\tseemed\tco...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: The\tquestion\tbroke\tthe\tsilence\tand\tI\tsnapped\tmy...\n",
      "> Adding chunk: The\tquestion\tbroke\tthe\tsilence\tand\tI\tsnapped\tmy...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: and\teventually\twe\tturned\ta\tcorner\tand\tthe\tsweet...\n",
      "> Adding chunk: and\teventually\twe\tturned\ta\tcorner\tand\tthe\tsweet...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: around\tin\tmy\tmouth\tto\tease\tthe\tburning.\tIt\twasn...\n",
      "> Adding chunk: around\tin\tmy\tmouth\tto\tease\tthe\tburning.\tIt\twasn...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 3\n",
      "\t\n",
      "“A\tcripple\tthinks\the’ll\tbe\table\tto\tride\ta\td...\n",
      "> Adding chunk: 3\n",
      "\t\n",
      "“A\tcripple\tthinks\the’ll\tbe\table\tto\tride\ta\td...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: “How\tdare\tyou\tspeak\tto\tme\tlike\tthat,\tlow\tborn!”...\n",
      "> Adding chunk: “How\tdare\tyou\tspeak\tto\tme\tlike\tthat,\tlow\tborn!”...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Maren\tleaned\tforward\tand\tlowered\ther\tvoice\tto\ta...\n",
      "> Adding chunk: Maren\tleaned\tforward\tand\tlowered\ther\tvoice\tto\ta...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: “Let’s\tgo,”\tI\tsaid.\n",
      "Maren\tnodded,\tthat\tblasted\t...\n",
      "> Adding chunk: “Let’s\tgo,”\tI\tsaid.\n",
      "Maren\tnodded,\tthat\tblasted\t...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: but\tI\tcouldn’t\tmake\tout\tthe\twords.\tThe\tmassive\t...\n",
      "> Adding chunk: but\tI\tcouldn’t\tmake\tout\tthe\twords.\tThe\tmassive\t...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: The\texit\tis\tbehind\tus.”\n",
      "“There\tis\talways\tmore\tt...\n",
      "> Adding chunk: The\texit\tis\tbehind\tus.”\n",
      "“There\tis\talways\tmore\tt...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: a\trope\tdown.\n",
      "“Try\tthis,”\tshe\tsaid.\n",
      "I\tgrabbed\tah...\n",
      "> Adding chunk: a\trope\tdown.\n",
      "“Try\tthis,”\tshe\tsaid.\n",
      "I\tgrabbed\tah...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 4\n",
      "\t\n",
      "A\tfew\thours\tlater,\tafter\tI\thad\tcleaned\tthe\t...\n",
      "> Adding chunk: 4\n",
      "\t\n",
      "A\tfew\thours\tlater,\tafter\tI\thad\tcleaned\tthe\t...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: in\tevery\tdirection\tbefore\tnodding\tto\thimself.\tT...\n",
      "> Adding chunk: in\tevery\tdirection\tbefore\tnodding\tto\thimself.\tT...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: refer\tyourselves\tback\tto\tmy\toriginal\tstatement\t...\n",
      "> Adding chunk: refer\tyourselves\tback\tto\tmy\toriginal\tstatement\t...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: looked\tcompletely\tdifferent\tfrom\twhat\tit\thad\tju...\n",
      "> Adding chunk: looked\tcompletely\tdifferent\tfrom\twhat\tit\thad\tju...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: couldn’t\thelp\tit.\tI\twas\tparched\tand\tdrank\tsever...\n",
      "> Adding chunk: couldn’t\thelp\tit.\tI\twas\tparched\tand\tdrank\tsever...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 5\n",
      "\t\n",
      "After\tthe\tceremony\twas\tover,\twe\tfollowed\tCu...\n",
      "> Adding chunk: 5\n",
      "\t\n",
      "After\tthe\tceremony\twas\tover,\twe\tfollowed\tCu...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: mastered\tthe\tskills\tnecessary\tto\tkeep\tfrom\tfall...\n",
      "> Adding chunk: mastered\tthe\tskills\tnecessary\tto\tkeep\tfrom\tfall...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: seventh\tbell,\tand\tthe\tthirteenth\tbell.\tIf\tyou\td...\n",
      "> Adding chunk: seventh\tbell,\tand\tthe\tthirteenth\tbell.\tIf\tyou\td...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: was\tneatly\tarranged\ton\tone\tside\tof\tthe\troom.\tI\t...\n",
      "> Adding chunk: was\tneatly\tarranged\ton\tone\tside\tof\tthe\troom.\tI\t...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: hadn’t\tsaid\tanything.\tHe\twas\ton\this\tbed,\this\tba...\n",
      "> Adding chunk: hadn’t\tsaid\tanything.\tHe\twas\ton\this\tbed,\this\tba...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 6\n",
      "\t\n",
      "I\tmanaged\tto\tget\tdown\tto\tthe\tdining\thall\tin...\n",
      "> Adding chunk: 6\n",
      "\t\n",
      "I\tmanaged\tto\tget\tdown\tto\tthe\tdining\thall\tin...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: “I\twanted\tto\tapologize\tfor\twhat\tI\tsaid\tlast\tnig...\n",
      "> Adding chunk: “I\twanted\tto\tapologize\tfor\twhat\tI\tsaid\tlast\tnig...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: “Well\tdone,\tSimon,”\tone\tof\tthe\tguards\tsaid.\t“I\t...\n",
      "> Adding chunk: “Well\tdone,\tSimon,”\tone\tof\tthe\tguards\tsaid.\t“I\t...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: me.\tI\tcould\tsmell\tthe\tleather\tof\this\tarmor,\talo...\n",
      "> Adding chunk: me.\tI\tcould\tsmell\tthe\tleather\tof\this\tarmor,\talo...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: swing,\twhich\tthrew\this\tmotion\toff.\tThe\tblade\tsw...\n",
      "> Adding chunk: swing,\twhich\tthrew\this\tmotion\toff.\tThe\tblade\tsw...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 7\n",
      "\t\n",
      "When\tI\tawoke,\tI\thad\tno\tidea\twhere\tI\twas.\n",
      "My...\n",
      "> Adding chunk: 7\n",
      "\t\n",
      "When\tI\tawoke,\tI\thad\tno\tidea\twhere\tI\twas.\n",
      "My...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: “I\twas\tbrowsing\tthe\tvendors.”\n",
      "“How\tdid\tyou\tend\t...\n",
      "> Adding chunk: “I\twas\tbrowsing\tthe\tvendors.”\n",
      "“How\tdid\tyou\tend\t...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: “I\thave\tto.\tThis\tis\tmy\tonly\tchance.”\tI\tcouldn’t...\n",
      "> Adding chunk: “I\thave\tto.\tThis\tis\tmy\tonly\tchance.”\tI\tcouldn’t...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: have\tto\task.\tDid\tyou\tuse\tmagic\tagainst\tthose\tgu...\n",
      "> Adding chunk: have\tto\task.\tDid\tyou\tuse\tmagic\tagainst\tthose\tgu...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: my\tbody\twas\tsore.\tBy\tthe\ttime\tI\treached\tthe\ttop...\n",
      "> Adding chunk: my\tbody\twas\tsore.\tBy\tthe\ttime\tI\treached\tthe\ttop...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 8\n",
      "\t\n",
      "I\trushed\tinto\tthe\ttemple.\n",
      "To\tmy\trelief,\teve...\n",
      "> Adding chunk: 8\n",
      "\t\n",
      "I\trushed\tinto\tthe\ttemple.\n",
      "To\tmy\trelief,\teve...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: but\tI\tam\tnot\tcompletely\tin\tcontrol\tof\tthe\ttest....\n",
      "> Adding chunk: but\tI\tam\tnot\tcompletely\tin\tcontrol\tof\tthe\ttest....\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: “Will\tyou\tplease\tjoin\tme\tup\there?”\n",
      "I\trecognized...\n",
      "> Adding chunk: “Will\tyou\tplease\tjoin\tme\tup\there?”\n",
      "I\trecognized...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: “I’m\tsorry,”\tshe\tsaid.\n",
      "I\tcould\tfeel\tmy\teyes\twel...\n",
      "> Adding chunk: “I’m\tsorry,”\tshe\tsaid.\n",
      "I\tcould\tfeel\tmy\teyes\twel...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: I\twalked\tto\tthe\tfront\tand\tfollowed\tthe\tmaster\tt...\n",
      "> Adding chunk: I\twalked\tto\tthe\tfront\tand\tfollowed\tthe\tmaster\tt...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 9\n",
      "\t\n",
      "I\twas\tin\tAutumnwick’s\tmarket.\n",
      "The\tCitadel\tt...\n",
      "> Adding chunk: 9\n",
      "\t\n",
      "I\twas\tin\tAutumnwick’s\tmarket.\n",
      "The\tCitadel\tt...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: duel\tit\tout\tbetween\tthemselves.\n",
      "“It’s\tthe\tlast\t...\n",
      "> Adding chunk: duel\tit\tout\tbetween\tthemselves.\n",
      "“It’s\tthe\tlast\t...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: held\tout\ta\tsilver\tcoin\tto\tme.\n",
      "“Please,\ttake\tthi...\n",
      "> Adding chunk: held\tout\ta\tsilver\tcoin\tto\tme.\n",
      "“Please,\ttake\tthi...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: It\twas\tbusiness\tas\tusual.\tWhen\tI\tlooked\tat\tthe\t...\n",
      "> Adding chunk: It\twas\tbusiness\tas\tusual.\tWhen\tI\tlooked\tat\tthe\t...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: it\twas\ttoo\tstrong.\tI\thad\tno\tidea\twhat\twas\thappe...\n",
      "> Adding chunk: it\twas\ttoo\tstrong.\tI\thad\tno\tidea\twhat\twas\thappe...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: “Yes,\tbut—”\n",
      "“No,”\the\tinterrupted\tagain,\this\tton...\n",
      "> Adding chunk: “Yes,\tbut—”\n",
      "“No,”\the\tinterrupted\tagain,\this\tton...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 10\n",
      "\t\n",
      "“Gods,”\tI\tbreathed.\n",
      "“What?”\tMaren\tasked.\t“...\n",
      "> Adding chunk: 10\n",
      "\t\n",
      "“Gods,”\tI\tbreathed.\n",
      "“What?”\tMaren\tasked.\t“...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: conversations\twere\tmuted,\tand\teveryone\tseemed\tt...\n",
      "> Adding chunk: conversations\twere\tmuted,\tand\teveryone\tseemed\tt...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: “Sorry,”\tI\tmumbled.\t“I\twas\tsupposed\tto\tmeet\tyou...\n",
      "> Adding chunk: “Sorry,”\tI\tmumbled.\t“I\twas\tsupposed\tto\tmeet\tyou...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: “I’ll\ttry\tto,”\tMaren\treplied.\t“Magic\tis\tlike\tth...\n",
      "> Adding chunk: “I’ll\ttry\tto,”\tMaren\treplied.\t“Magic\tis\tlike\tth...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: away\twith\ta\tspell\tthat\tcreated\ta\twall\tor\tsometh...\n",
      "> Adding chunk: away\twith\ta\tspell\tthat\tcreated\ta\twall\tor\tsometh...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 11\n",
      "\t\n",
      "Maren\tstared\tat\tme\tin\tdisbelief.\n",
      "“You\treal...\n",
      "> Adding chunk: 11\n",
      "\t\n",
      "Maren\tstared\tat\tme\tin\tdisbelief.\n",
      "“You\treal...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: then.”\n",
      "I\tknew\tI\tcouldn’t\tlet\ther\tdo\tthat,\tbut\tI...\n",
      "> Adding chunk: then.”\n",
      "I\tknew\tI\tcouldn’t\tlet\ther\tdo\tthat,\tbut\tI...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: “Perhaps\tsending\ta\tscout\tor\ttwo\tto\tcheck\tthings...\n",
      "> Adding chunk: “Perhaps\tsending\ta\tscout\tor\ttwo\tto\tcheck\tthings...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: doesn’t\teven\tknow\tshe’s\tgone.”\n",
      "“Then\twe\tfeign\ti...\n",
      "> Adding chunk: doesn’t\teven\tknow\tshe’s\tgone.”\n",
      "“Then\twe\tfeign\ti...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: school\tfor\ta\tfew\tdays.\tIt\tseemed\tthat\tmore\tmyst...\n",
      "> Adding chunk: school\tfor\ta\tfew\tdays.\tIt\tseemed\tthat\tmore\tmyst...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 12\n",
      "\t\n",
      "The\tlibrary\twas\tlocated\tat\tthe\tfar\tnorth\te...\n",
      "> Adding chunk: 12\n",
      "\t\n",
      "The\tlibrary\twas\tlocated\tat\tthe\tfar\tnorth\te...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: specific\ttopic,\tyou\tcan\tsearch\tthe\tindex\tfor\tbo...\n",
      "> Adding chunk: specific\ttopic,\tyou\tcan\tsearch\tthe\tindex\tfor\tbo...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: was\tglad\tthat\tmy\tmother\thad\ttaught\tme\tto\tread\ta...\n",
      "> Adding chunk: was\tglad\tthat\tmy\tmother\thad\ttaught\tme\tto\tread\ta...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: lacking\tthe\tbook\tI\tneeded.\n",
      "I\tscratched\tmy\tchin\t...\n",
      "> Adding chunk: lacking\tthe\tbook\tI\tneeded.\n",
      "I\tscratched\tmy\tchin\t...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: every\tbook\ton\tthe\tFalse\tKing\twas\tinexplicably\tm...\n",
      "> Adding chunk: every\tbook\ton\tthe\tFalse\tKing\twas\tinexplicably\tm...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 13\n",
      "\t\n",
      "“Who\twould\tbe\ttrying\tto\thide\tsomething\trel...\n",
      "> Adding chunk: 13\n",
      "\t\n",
      "“Who\twould\tbe\ttrying\tto\thide\tsomething\trel...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: fine.\tI\tcan\tdo\tit\talone.”\tShe\tstood\tup\tand\tleft...\n",
      "> Adding chunk: fine.\tI\tcan\tdo\tit\talone.”\tShe\tstood\tup\tand\tleft...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: next\tthing\tI\tknew,\tMaren\twas\tjabbing\tme\twith\the...\n",
      "> Adding chunk: next\tthing\tI\tknew,\tMaren\twas\tjabbing\tme\twith\the...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: She\tpushed\ton\tone\tof\tthe\tbricks\tin\tthe\twall\tand...\n",
      "> Adding chunk: She\tpushed\ton\tone\tof\tthe\tbricks\tin\tthe\twall\tand...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: battled\tthe\tboy\tin\tmy\tCompassion\ttest.\tDread\tst...\n",
      "> Adding chunk: battled\tthe\tboy\tin\tmy\tCompassion\ttest.\tDread\tst...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: then\tthat\tthe\tfigure\tfrom\tmy\ttest\tand\tthe\tone\ts...\n",
      "> Adding chunk: then\tthat\tthe\tfigure\tfrom\tmy\ttest\tand\tthe\tone\ts...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: “Can\tyou\tbreak\tthe\tspell?”\tI\tasked.\n",
      "“No.\tIt’s\tp...\n",
      "> Adding chunk: “Can\tyou\tbreak\tthe\tspell?”\tI\tasked.\n",
      "“No.\tIt’s\tp...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 14\n",
      "\t\n",
      "Master\tPevus\tlistened\tto\tMaren’s\ttale\twith...\n",
      "> Adding chunk: 14\n",
      "\t\n",
      "Master\tPevus\tlistened\tto\tMaren’s\ttale\twith...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: “How\tdo\tyou\tknow\tof\tthe\thidden\troom?”\the\tasked....\n",
      "> Adding chunk: “How\tdo\tyou\tknow\tof\tthe\thidden\troom?”\the\tasked....\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: “What\tis\tthat\tstuff?”\tI\tasked.\n",
      "“Charcoal.”\n",
      "“Why...\n",
      "> Adding chunk: “What\tis\tthat\tstuff?”\tI\tasked.\n",
      "“Charcoal.”\n",
      "“Why...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: about\tJosephine,\tso\tit’s\tgoing\tto\tbe\tdifficult\t...\n",
      "> Adding chunk: about\tJosephine,\tso\tit’s\tgoing\tto\tbe\tdifficult\t...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: “What’s\twrong?”\tI\tasked.\n",
      "“I\tcan’t\thelp\tbut\tthin...\n",
      "> Adding chunk: “What’s\twrong?”\tI\tasked.\n",
      "“I\tcan’t\thelp\tbut\tthin...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 15\n",
      "\t\n",
      "When\tthe\tbell\trang\tfor\tbreakfast\tin\tthe\tmo...\n",
      "> Adding chunk: 15\n",
      "\t\n",
      "When\tthe\tbell\trang\tfor\tbreakfast\tin\tthe\tmo...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: you’re\tright.”\n",
      "Curate\tAnesko\tcleared\this\tthroat...\n",
      "> Adding chunk: you’re\tright.”\n",
      "Curate\tAnesko\tcleared\this\tthroat...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Anesko\tordered\tus\tto\tsit\tand\twe\tobeyed.\tThe\twal...\n",
      "> Adding chunk: Anesko\tordered\tus\tto\tsit\tand\twe\tobeyed.\tThe\twal...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: eyes.\tThe\twind\tfelt\tamazing\tagainst\tmy\tface.\tI\t...\n",
      "> Adding chunk: eyes.\tThe\twind\tfelt\tamazing\tagainst\tmy\tface.\tI\t...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: “Oh.\tThat’s\tinteresting.\tWhat\tabout\tgreen\tones?...\n",
      "> Adding chunk: “Oh.\tThat’s\tinteresting.\tWhat\tabout\tgreen\tones?...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: looked\tat\tit,\tthen\tput\tit\tto\tmy\tmouth\tand\tlifte...\n",
      "> Adding chunk: looked\tat\tit,\tthen\tput\tit\tto\tmy\tmouth\tand\tlifte...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 16\n",
      "\t\n",
      "Magic\thummed\tin\tmy\tears.\n",
      "It\twasn’t\toverly\t...\n",
      "> Adding chunk: 16\n",
      "\t\n",
      "Magic\thummed\tin\tmy\tears.\n",
      "It\twasn’t\toverly\t...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: magic.\n",
      "And\tthen\tthe\tresistance\twas\tgone\tcomplet...\n",
      "> Adding chunk: magic.\n",
      "And\tthen\tthe\tresistance\twas\tgone\tcomplet...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: continued\tmoving.\tThe\tcreature\tdidn’t\tstop.\tIt\t...\n",
      "> Adding chunk: continued\tmoving.\tThe\tcreature\tdidn’t\tstop.\tIt\t...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: After\ta\tfew\tmoments\tof\tpanic,\tthe\tweakness\twent...\n",
      "> Adding chunk: After\ta\tfew\tmoments\tof\tpanic,\tthe\tweakness\twent...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Pevus\tnor\tthe\tCurates\twould\thave\tallowed\tsuch\ta...\n",
      "> Adding chunk: Pevus\tnor\tthe\tCurates\twould\thave\tallowed\tsuch\ta...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: gargoyle’s\tbroken\tbody\tand\tcouldn’t\thelp\tbut\two...\n",
      "> Adding chunk: gargoyle’s\tbroken\tbody\tand\tcouldn’t\thelp\tbut\two...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 17\n",
      "\t\n",
      "I\twas\tsitting\tin\ta\tsmall\troom\toutside\tMast...\n",
      "> Adding chunk: 17\n",
      "\t\n",
      "I\twas\tsitting\tin\ta\tsmall\troom\toutside\tMast...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: That\tleaves\tonly\tone\texplanation.”\n",
      "I\twaited\tfor...\n",
      "> Adding chunk: That\tleaves\tonly\tone\texplanation.”\n",
      "I\twaited\tfor...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: deal\twith\tthe\tFalse\tKing.\tNow,\tyou\tshould\tget\ts...\n",
      "> Adding chunk: deal\twith\tthe\tFalse\tKing.\tNow,\tyou\tshould\tget\ts...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: midnight\twhen\tI\tclimbed\tinto\tmy\tbed.\tI\tdrifted\t...\n",
      "> Adding chunk: midnight\twhen\tI\tclimbed\tinto\tmy\tbed.\tI\tdrifted\t...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: likely\tto\tbe\tlate\tand\tthen\t…”\tI\ttrailed\toff\twhe...\n",
      "> Adding chunk: likely\tto\tbe\tlate\tand\tthen\t…”\tI\ttrailed\toff\twhe...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: waiting\tfor\tthe\trest\tof\this\tinstructions.\n",
      "“Well...\n",
      "> Adding chunk: waiting\tfor\tthe\trest\tof\this\tinstructions.\n",
      "“Well...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 18\n",
      "\t\n",
      "By\tthe\ttime\tI’d\tmade\tit\taround\tthe\tentire\t...\n",
      "> Adding chunk: 18\n",
      "\t\n",
      "By\tthe\ttime\tI’d\tmade\tit\taround\tthe\tentire\t...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: intensely.\tI\thung\tin\tplace\tand\tmy\tarms\twere\tsha...\n",
      "> Adding chunk: intensely.\tI\thung\tin\tplace\tand\tmy\tarms\twere\tsha...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: “Let\tme\tsay\tthis:\tif\tyou\tare\tinjured\tto\tthe\tpoi...\n",
      "> Adding chunk: “Let\tme\tsay\tthis:\tif\tyou\tare\tinjured\tto\tthe\tpoi...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: “I\tlearned\thow\tto\tdefend\tmyself\tfrom\tthe\tcaptai...\n",
      "> Adding chunk: “I\tlearned\thow\tto\tdefend\tmyself\tfrom\tthe\tcaptai...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: brutal\tthings\tthan\twhat\tthis\ttest\toffered.\tStil...\n",
      "> Adding chunk: brutal\tthings\tthan\twhat\tthis\ttest\toffered.\tStil...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 19\n",
      "\t\n",
      "It\tonly\ttook\tme\ta\tmoment\tto\tdecide\tthat\tI\t...\n",
      "> Adding chunk: 19\n",
      "\t\n",
      "It\tonly\ttook\tme\ta\tmoment\tto\tdecide\tthat\tI\t...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: made\tthings\tworse\tbecause\tof\tthe\tmud\ton\tthe\tgar...\n",
      "> Adding chunk: made\tthings\tworse\tbecause\tof\tthe\tmud\ton\tthe\tgar...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: “By\taccident\t…\tbut\tthe\topen\tdoor\tof\tthe\tbuildin...\n",
      "> Adding chunk: “By\taccident\t…\tbut\tthe\topen\tdoor\tof\tthe\tbuildin...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: “Yes.”\n",
      "“And\tyou\tcame\there\tto\thelp\ther\teven\tthou...\n",
      "> Adding chunk: “Yes.”\n",
      "“And\tyou\tcame\there\tto\thelp\ther\teven\tthou...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: wouldn’t.\tShe\twas\ttoo\tconflicted\twith\therself\tt...\n",
      "> Adding chunk: wouldn’t.\tShe\twas\ttoo\tconflicted\twith\therself\tt...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 20\n",
      "\t\n",
      "I\tdidn’t\tknow\thow\tmuch\ttime\thad\tpassed\twhe...\n",
      "> Adding chunk: 20\n",
      "\t\n",
      "I\tdidn’t\tknow\thow\tmuch\ttime\thad\tpassed\twhe...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Master\tPevus\tseemed\tlike\the\twas\tabout\tto\tobject...\n",
      "> Adding chunk: Master\tPevus\tseemed\tlike\the\twas\tabout\tto\tobject...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: and\talmost\tlost\tmy\tgrip\ton\tthe\thilt.\tAlthough\tm...\n",
      "> Adding chunk: and\talmost\tlost\tmy\tgrip\ton\tthe\thilt.\tAlthough\tm...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: As\tsoon\tas\tSebastian\tturned\n",
      "his\tback\tto\tme,\tI\ts...\n",
      "> Adding chunk: As\tsoon\tas\tSebastian\tturned\n",
      "his\tback\tto\tme,\tI\ts...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: his\tblade.\tI\twent\tafter\thim,\tbut\the\twas\tquicker...\n",
      "> Adding chunk: his\tblade.\tI\twent\tafter\thim,\tbut\the\twas\tquicker...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: how\tI\twould\tescape\tthe\tCitadel\tbefore\tMaster\tPe...\n",
      "> Adding chunk: how\tI\twould\tescape\tthe\tCitadel\tbefore\tMaster\tPe...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 21\n",
      "\t\n",
      "The\tnext\tmorning,\tI\tawoke\tbleary-eyed\tand\t...\n",
      "> Adding chunk: 21\n",
      "\t\n",
      "The\tnext\tmorning,\tI\tawoke\tbleary-eyed\tand\t...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: were\tbags\tunder\this\teyes,\tand\tI\tguessed\tthat\the...\n",
      "> Adding chunk: were\tbags\tunder\this\teyes,\tand\tI\tguessed\tthat\the...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: “Yes,\tMaster.\tIt\tdoes\tseem\todd\tto\tme\tthat\twe’re...\n",
      "> Adding chunk: “Yes,\tMaster.\tIt\tdoes\tseem\todd\tto\tme\tthat\twe’re...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: be\thard\tto\ttell\tin\tthis\tlight.”\n",
      "“Hello\tPhlandyr...\n",
      "> Adding chunk: be\thard\tto\ttell\tin\tthis\tlight.”\n",
      "“Hello\tPhlandyr...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: locked\tin\ta\troom\tsomewhere,\tnot\tout\tin\tthe\topen...\n",
      "> Adding chunk: locked\tin\ta\troom\tsomewhere,\tnot\tout\tin\tthe\topen...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Time\twas\tmy\tenemy.\tI\tturned\tand\tswam\tfor\tthe\tsh...\n",
      "> Adding chunk: Time\twas\tmy\tenemy.\tI\tturned\tand\tswam\tfor\tthe\tsh...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: The\tjourney\tcontinues\twith\tA\tBond\tof\tFlame,\tava...\n",
      "> Adding chunk: The\tjourney\tcontinues\twith\tA\tBond\tof\tFlame,\tava...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: OTHER\tBOOKS\n",
      "\t\n",
      "Hey\tthere!\n",
      "I\twrite\tfantasy\tand\tsp...\n",
      "> Adding chunk: OTHER\tBOOKS\n",
      "\t\n",
      "Hey\tthere!\n",
      "I\twrite\tfantasy\tand\tsp...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Shard\tof\tthe\tSun\n",
      "\t\n",
      "SPACE\tOPERA\n",
      "Galactic\tMercena...\n",
      "> Adding chunk: Shard\tof\tthe\tSun\n",
      "\t\n",
      "SPACE\tOPERA\n",
      "Galactic\tMercena...\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): us-api.i.posthog.com:443\n",
      "Starting new HTTPS connection (1): us-api.i.posthog.com:443\n",
      "INFO:backoff:Backing off send_request(...) for 0.5s (requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='us-api.i.posthog.com', port=443): Max retries exceeded with url: /batch/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001CB9CB88050>, 'Connection to us-api.i.posthog.com timed out. (connect timeout=15)')))\n",
      "Backing off send_request(...) for 0.5s (requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='us-api.i.posthog.com', port=443): Max retries exceeded with url: /batch/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001CB9CB88050>, 'Connection to us-api.i.posthog.com timed out. (connect timeout=15)')))\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (2): us-api.i.posthog.com:443\n",
      "Starting new HTTPS connection (2): us-api.i.posthog.com:443\n",
      "INFO:backoff:Backing off send_request(...) for 0.1s (requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='us-api.i.posthog.com', port=443): Max retries exceeded with url: /batch/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001CB9C795ED0>, 'Connection to us-api.i.posthog.com timed out. (connect timeout=15)')))\n",
      "Backing off send_request(...) for 0.1s (requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='us-api.i.posthog.com', port=443): Max retries exceeded with url: /batch/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001CB9C795ED0>, 'Connection to us-api.i.posthog.com timed out. (connect timeout=15)')))\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (3): us-api.i.posthog.com:443\n",
      "Starting new HTTPS connection (3): us-api.i.posthog.com:443\n",
      "INFO:backoff:Backing off send_request(...) for 0.6s (requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='us-api.i.posthog.com', port=443): Max retries exceeded with url: /batch/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001CB9CB73FD0>, 'Connection to us-api.i.posthog.com timed out. (connect timeout=15)')))\n",
      "Backing off send_request(...) for 0.6s (requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='us-api.i.posthog.com', port=443): Max retries exceeded with url: /batch/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001CB9CB73FD0>, 'Connection to us-api.i.posthog.com timed out. (connect timeout=15)')))\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (4): us-api.i.posthog.com:443\n",
      "Starting new HTTPS connection (4): us-api.i.posthog.com:443\n",
      "ERROR:backoff:Giving up send_request(...) after 4 tries (requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='us-api.i.posthog.com', port=443): Max retries exceeded with url: /batch/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001CBA4127F90>, 'Connection to us-api.i.posthog.com timed out. (connect timeout=15)')))\n",
      "Giving up send_request(...) after 4 tries (requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='us-api.i.posthog.com', port=443): Max retries exceeded with url: /batch/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001CBA4127F90>, 'Connection to us-api.i.posthog.com timed out. (connect timeout=15)')))\n",
      "DEBUG:chromadb.config:Starting component LocalHnswSegment\n",
      "Starting component LocalHnswSegment\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (5): us-api.i.posthog.com:443\n",
      "Starting new HTTPS connection (5): us-api.i.posthog.com:443\n",
      "CPU times: total: 30min 8s\n",
      "Wall time: 8min 56s\n",
      "INFO:backoff:Backing off send_request(...) for 0.5s (requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='us-api.i.posthog.com', port=443): Max retries exceeded with url: /batch/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001CB9C7E8AD0>, 'Connection to us-api.i.posthog.com timed out. (connect timeout=15)')))\n",
      "Backing off send_request(...) for 0.5s (requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='us-api.i.posthog.com', port=443): Max retries exceeded with url: /batch/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001CB9C7E8AD0>, 'Connection to us-api.i.posthog.com timed out. (connect timeout=15)')))\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (6): us-api.i.posthog.com:443\n",
      "Starting new HTTPS connection (6): us-api.i.posthog.com:443\n",
      "INFO:backoff:Backing off send_request(...) for 0.1s (requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='us-api.i.posthog.com', port=443): Max retries exceeded with url: /batch/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001CBCDA3D310>, 'Connection to us-api.i.posthog.com timed out. (connect timeout=15)')))\n",
      "Backing off send_request(...) for 0.1s (requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='us-api.i.posthog.com', port=443): Max retries exceeded with url: /batch/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001CBCDA3D310>, 'Connection to us-api.i.posthog.com timed out. (connect timeout=15)')))\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (7): us-api.i.posthog.com:443\n",
      "Starting new HTTPS connection (7): us-api.i.posthog.com:443\n",
      "INFO:backoff:Backing off send_request(...) for 0.2s (requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='us-api.i.posthog.com', port=443): Max retries exceeded with url: /batch/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001CB9CA36E50>, 'Connection to us-api.i.posthog.com timed out. (connect timeout=15)')))\n",
      "Backing off send_request(...) for 0.2s (requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='us-api.i.posthog.com', port=443): Max retries exceeded with url: /batch/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001CB9CA36E50>, 'Connection to us-api.i.posthog.com timed out. (connect timeout=15)')))\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (8): us-api.i.posthog.com:443\n",
      "Starting new HTTPS connection (8): us-api.i.posthog.com:443\n",
      "ERROR:backoff:Giving up send_request(...) after 4 tries (requests.exceptions.ConnectionError: HTTPSConnectionPool(host='us-api.i.posthog.com', port=443): Max retries exceeded with url: /batch/ (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001CBACAE67D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')))\n",
      "Giving up send_request(...) after 4 tries (requests.exceptions.ConnectionError: HTTPSConnectionPool(host='us-api.i.posthog.com', port=443): Max retries exceeded with url: /batch/ (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001CBACAE67D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')))\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from pathlib import Path\n",
    "import glob\n",
    "from llama_index.core import SimpleDirectoryReader, ServiceContext, StorageContext, VectorStoreIndex, download_loader\n",
    "import chromadb\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "\n",
    "PDFReader = download_loader('PDFReader')\n",
    "loader = PDFReader()\n",
    "\n",
    "documents = loader.load_data(file=Path(\"./Trial-by-Sorcery.pdf\"))\n",
    "\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm=llm,\n",
    "    embed_model=embedding_model,\n",
    "    system_prompt='You are a bot that answers questions about the book.'\n",
    ")\n",
    "\n",
    "# create client and a new collection\n",
    "chroma_client = chromadb.EphemeralClient()\n",
    "\n",
    "\n",
    "chroma_collection = chroma_client.get_or_create_collection(\"quickstart\")\n",
    "chroma_client.delete_collection(\"quickstart\")\n",
    "chroma_collection = chroma_client.get_or_create_collection(\"quickstart\")\n",
    "\n",
    "# set up ChromaVectorStore and load in data\n",
    "vector_store2 = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context2 = StorageContext.from_defaults(vector_store=vector_store2)\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, storage_context=storage_context2, embed_model=embedding_model, service_context=service_context\n",
    ")\n",
    "\n",
    "# Query Data\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4822cbb-1dc4-447a-aec5-bbf9f2ecbd6d",
   "metadata": {
    "id": "b4822cbb-1dc4-447a-aec5-bbf9f2ecbd6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:llama_index.vector_stores.chroma.base:> Top 1 nodes:\n",
      "> Top 1 nodes:\n",
      "DEBUG:llama_index.vector_stores.chroma.base:> [Node f63e8ccc-d890-476d-923f-1b91637d1ebc] [Similarity score: 0.5236360740421369] 2\n",
      "\t\n",
      "The\tentrance\tto\tthe\tCitadel\twas\tmuch\tmore\theavily\tguarded\tthan\tthe\tcity\n",
      "gates.\tAnd\tthese\tguar...\n",
      "> [Node f63e8ccc-d890-476d-923f-1b91637d1ebc] [Similarity score: 0.5236360740421369] 2\n",
      "\t\n",
      "The\tentrance\tto\tthe\tCitadel\twas\tmuch\tmore\theavily\tguarded\tthan\tthe\tcity\n",
      "gates.\tAnd\tthese\tguar...\n",
      "DEBUG:llama_index.vector_stores.chroma.base:> [Node ff614cd2-0e73-45dd-a50b-451d0cc90501] [Similarity score: 0.46177424703594677] 1\n",
      "\t\n",
      "I\tmarveled\tat\tthe\tvastness\tof\tthe\tCitadel.\n",
      "It\twas\thome\tto\tthe\tDragon\tGuard,\tthe\tgreatest\twarr...\n",
      "> [Node ff614cd2-0e73-45dd-a50b-451d0cc90501] [Similarity score: 0.46177424703594677] 1\n",
      "\t\n",
      "I\tmarveled\tat\tthe\tvastness\tof\tthe\tCitadel.\n",
      "It\twas\thome\tto\tthe\tDragon\tGuard,\tthe\tgreatest\twarr...\n",
      "DEBUG:llama_index.core.indices.utils:> Top 2 nodes:\n",
      "> [Node f63e8ccc-d890-476d-923f-1b91637d1ebc] [Similarity score:             0.523636] 2\n",
      "\t\n",
      "The\tentrance\tto\tthe\tCitadel\twas\tmuch\tmore\theavily\tguarded\tthan\tthe\tcity\n",
      "gates.\tAnd\tthese\tguar...\n",
      "> [Node ff614cd2-0e73-45dd-a50b-451d0cc90501] [Similarity score:             0.461774] 1\n",
      "\t\n",
      "I\tmarveled\tat\tthe\tvastness\tof\tthe\tCitadel.\n",
      "It\twas\thome\tto\tthe\tDragon\tGuard,\tthe\tgreatest\twarr...\n",
      "> Top 2 nodes:\n",
      "> [Node f63e8ccc-d890-476d-923f-1b91637d1ebc] [Similarity score:             0.523636] 2\n",
      "\t\n",
      "The\tentrance\tto\tthe\tCitadel\twas\tmuch\tmore\theavily\tguarded\tthan\tthe\tcity\n",
      "gates.\tAnd\tthese\tguar...\n",
      "> [Node ff614cd2-0e73-45dd-a50b-451d0cc90501] [Similarity score:             0.461774] 1\n",
      "\t\n",
      "I\tmarveled\tat\tthe\tvastness\tof\tthe\tCitadel.\n",
      "It\twas\thome\tto\tthe\tDragon\tGuard,\tthe\tgreatest\twarr...\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (9): us-api.i.posthog.com:443\n",
      "Starting new HTTPS connection (9): us-api.i.posthog.com:443\n",
      "INFO:backoff:Backing off send_request(...) for 0.4s (requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='us-api.i.posthog.com', port=443): Max retries exceeded with url: /batch/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001CB9CA36FD0>, 'Connection to us-api.i.posthog.com timed out. (connect timeout=15)')))\n",
      "Backing off send_request(...) for 0.4s (requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='us-api.i.posthog.com', port=443): Max retries exceeded with url: /batch/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001CB9CA36FD0>, 'Connection to us-api.i.posthog.com timed out. (connect timeout=15)')))\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (10): us-api.i.posthog.com:443\n",
      "Starting new HTTPS connection (10): us-api.i.posthog.com:443\n",
      "INFO:backoff:Backing off send_request(...) for 0.1s (requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='us-api.i.posthog.com', port=443): Max retries exceeded with url: /batch/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001CB9CA05990>, 'Connection to us-api.i.posthog.com timed out. (connect timeout=15)')))\n",
      "Backing off send_request(...) for 0.1s (requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='us-api.i.posthog.com', port=443): Max retries exceeded with url: /batch/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001CB9CA05990>, 'Connection to us-api.i.posthog.com timed out. (connect timeout=15)')))\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (11): us-api.i.posthog.com:443\n",
      "Starting new HTTPS connection (11): us-api.i.posthog.com:443\n",
      "INFO:backoff:Backing off send_request(...) for 2.0s (requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='us-api.i.posthog.com', port=443): Max retries exceeded with url: /batch/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001CBACAE7210>, 'Connection to us-api.i.posthog.com timed out. (connect timeout=15)')))\n",
      "Backing off send_request(...) for 2.0s (requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='us-api.i.posthog.com', port=443): Max retries exceeded with url: /batch/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001CBACAE7210>, 'Connection to us-api.i.posthog.com timed out. (connect timeout=15)')))\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (12): us-api.i.posthog.com:443\n",
      "Starting new HTTPS connection (12): us-api.i.posthog.com:443\n",
      "ERROR:backoff:Giving up send_request(...) after 4 tries (requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='us-api.i.posthog.com', port=443): Max retries exceeded with url: /batch/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001CB9CB658D0>, 'Connection to us-api.i.posthog.com timed out. (connect timeout=15)')))\n",
      "Giving up send_request(...) after 4 tries (requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='us-api.i.posthog.com', port=443): Max retries exceeded with url: /batch/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001CB9CB658D0>, 'Connection to us-api.i.posthog.com timed out. (connect timeout=15)')))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  319191.34 ms\n",
      "llama_print_timings:      sample time =      52.61 ms /    81 runs   (    0.65 ms per token,  1539.72 tokens per second)\n",
      "llama_print_timings: prompt eval time = 1238109.03 ms /  1899 tokens (  651.98 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:        eval time =  226191.64 ms /    80 runs   ( 2827.40 ms per token,     0.35 tokens per second)\n",
      "llama_print_timings:       total time = 1466429.76 ms /  1979 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Prompt: **\n",
      "You are a bot that answers questions about the book.\n",
      "\n",
      "Context information is below.\n",
      "---------------------\n",
      "page_label: 11\n",
      "file_name: Trial-by-Sorcery.pdf\n",
      "\n",
      "2\n",
      "\t\n",
      "The\tentrance\tto\tthe\tCitadel\twas\tmuch\tmore\theavily\tguarded\tthan\tthe\tcity\n",
      "gates.\tAnd\tthese\tguards\tweren’t\tthe\tcity\tguard,\teither.\tThey\twere\tDragon\n",
      "Guards.\tTheir\tarmor\twas\tdecorated\tto\tlook\tlike\tdragon\tscales,\tbut\tit\twas\n",
      "versatile\tand\tpractical\tfor\tbattle.\tBehind\tthe\tassemblage\tof\tguards\twas\ta\tlong\n",
      "wooden\ttable\tthat\thad\tweapons\tscattered\thaphazardly\ton\tits\tsurface.\n",
      "As\tI\tdrew\tnearer,\tthere\twas\ta\t\n",
      "whooshing\n",
      "\tsound\tthat\techoed\toff\tthe\tmassive\n",
      "walls\tand\tmade\tthe\titems\ton\tthe\ttable\tclatter.\tThe\tguards\tseemed\n",
      "unperturbed\tby\tthe\tnoise,\tbut\tI\twas\ttrying\tto\tfigure\tout\twhat\tit\twas\tand\n",
      "where\tit\twas\tcoming\tfrom.\tSuddenly,\ta\tmassive\tblue\tdragon\tswooped\tdown\n",
      "from\tthe\tsky\tand\tlanded\tin\tthe\tcourtyard.\n",
      "I\theld\tmy\tbreath\tin\tawe\tas\tI\tstared\tat\tthe\tpowerful\tbeast.\tIt\twas\teasily\n",
      "thirty\tfeet\tlong\tfrom\tits\tnose\tto\tits\ttail.\tThe\tdragon’s\trider\tslid\toff\tthe\tbeast’s\n",
      "back\tfrom\tthe\tshoulder\tand\tlanded\ton\tthe\tground\tgracefully.\tI\tsnapped\tmy\n",
      "mouth\tclosed\tand\tblinked\tseveral\ttimes.\tIn\tall\tthe\tyears\tmy\tfather\thad\tbeen\ta\n",
      "dragoon,\tI\tnever\thad\tthe\tchance\tto\tsee\this\tdragon.\tAside\tfrom\twhen\tthe\n",
      "guards\ttraveled\tthe\tkingdom,\tdragons\twere\tto\tbe\tkept\tat\tthe\tCitadel\tunder\n",
      "lock\tand\tkey.\tI\tdidn’t\tknow\twhy,\tthough.\n",
      "Now\tthat\tI\twas\tstanding\tbefore\ta\tdragon,\tI\tcould\thardly\tfathom\thow\tbig\tit\n",
      "was.\tIts\tshoulder\twas\tsix\tfeet\tabove\tthe\tground\tand\tits\twingspan\twas\n",
      "massive.\tI\ttried\tto\teyeball\tthe\tlength,\tbut\tit\thad\tto\tbe\talmost\ta\thundred\tfeet\n",
      "across.\tMy\tfocus\ton\tthe\tdragon\twas\tbroken\tas\tthe\tguards\tgot\tmy\tattention.\n",
      "“Hey\tthere,”\tone\tof\tthem\tcalled\tout.\t“Step\tforward.”\n",
      "I\tdid\tas\the\tasked\tand\twalked\tcloser,\tbut\tmy\tgaze\tremained\tlocked\ton\tthe\n",
      "dragon.\tAn\tolder\tman\tapproached\tthe\tcreature\tand\ttook\tits\treins,\tthen\tled\tit\n",
      "around\tthe\tback\tof\tthe\tcastle.\tWith\ta\tswish\tof\tits\ttail,\tthe\tdragon\tdisappeared\n",
      "behind\tthe\tfortress\tand\tI\tlooked\tat\tthe\tguard\twho’d\tspoken.\n",
      "“First\ttime,\thuh?”\the\tgrinned.\t“I\tremember\tmy\tfirst\ttime\tseeing\ta\tdragon,\n",
      "too.\tIt’s\tsomething\tyou\tnever\tforget.”\n",
      "\n",
      "page_label: 5\n",
      "file_name: Trial-by-Sorcery.pdf\n",
      "\n",
      "1\n",
      "\t\n",
      "I\tmarveled\tat\tthe\tvastness\tof\tthe\tCitadel.\n",
      "It\twas\thome\tto\tthe\tDragon\tGuard,\tthe\tgreatest\twarriors\tof\tthe\tkingdom.\n",
      "While\tthat\twas\timpressive\talone,\tit\twas\tmade\teven\tmore\tamazing\tbecause\tit\n",
      "was\talso\tthe\thome\tof\tdragons.\tThe\tmassive,\tpowerful\tcreatures\twere\tkept\tin\n",
      "the\tlower\tchamber\tof\tthe\tcastle.\tAt\tleast,\tthat’s\twhat\tmy\tfather\tused\tto\ttell\n",
      "me.\n",
      "A\twall\tforty\tfeet\thigh\tsurrounded\tthe\tcity\tof\tAutumnwick,\tas\twell\tas\tthe\n",
      "stone\tfortress\tthat\ttowered\tbehind\tit.\tThis\twas\tmy\tfirst\ttime\tseeing\tthe\tplace,\n",
      "and\tit\twas\tjust\tas\tlarge\tand\timposing\tas\tI’d\talways\timagined\tit\tto\tbe.\tThe\n",
      "massive\tgates\tthat\tprovided\tentrance\tthrough\tthe\twall\twere\tmanned\twith\n",
      "guards\tarmed\tto\tthe\tteeth.\tA\tsmall\tline\thad\tformed\tat\tthe\tentrance\tas\tthe\n",
      "guards\tchecked\teveryone\tentering.\n",
      "I\ttraveled\tdownhill\tand\tjoined\tthe\tline,\tadjusting\tmy\tsword\tbelt.\tThe\n",
      "weight\tof\tthe\tblade\tcontinuously\tpulled\tdown\ton\tmy\tpants.\tIt\tmade\tme\n",
      "reconsider\tmy\tdecision\tto\tuse\ta\tside\tsheath\tinstead\tof\tone\tthat\twent\tover\tthe\n",
      "shoulder.\tIt\twas\ttoo\tlate\tto\tchange\tmy\tmind\tnow.\tI’d\tspent\tthe\tlast\tof\tmy\n",
      "coins\tto\treach\tthe\tCitadel,\tand\tI\tdoubted\tthe\tschool\twould\tallow\tme\tto\tcarry\n",
      "a\tblade\tduring\tmy\ttraining\tanyway.\n",
      "The\tline\tshuffled\tforward\tslowly.\tI\tdid\tmy\tbest\tto\tremain\tpatient,\tbut\tit\n",
      "was\tdifficult.\tI\twas\tfinally\there!\tThe\thome\tof\tthe\tDragon\tGuard!\tI’d\tdreamed\n",
      "of\tjoining\ttheir\tranks\tfor\tas\tlong\tas\tI\tcould\tremember.\tMy\tfather’s\tstories\thad\n",
      "always\tbeen\tfilled\twith\tawe\tand\twonder\tas\the\tdescribed\this\tdragon\tand\tthe\n",
      "bond\tthey\tshared.\n",
      "Although\tit\twas\tstill\tearly\tin\tthe\tday,\tthe\tsky\twas\tclear\tand\tthe\tsun\tbeat\n",
      "down\tmercilessly.\tI\tcould\tfeel\tdroplets\tof\tsweat\trunning\tdown\tmy\tback\tand\n",
      "sides.\tI\tdrank\tthe\tlast\tof\tthe\twater\tin\tmy\tcanteen\tand\tcontinued\tto\twait.\tAfter\n",
      "what\tfelt\tlike\tan\teternity\tof\tbaking\tin\tthe\tsun,\tI\twas\tnext\tfor\tinspection.\tI\n",
      "glanced\tbehind\tme\tand\tsaw\tthe\tline\twas\tmuch\tlonger\tnow.\tThere\twere\tat\n",
      "---------------------\n",
      "Given the context information and not prior knowledge, answer the query.\n",
      "Query: What is a Dragon Guard?\n",
      "Answer: \n",
      "**************************************************\n",
      "** Completion: **\n",
      "\n",
      "A Dragon Guard is a warrior from the kingdom who is part of an elite group, known for their versatile and practical armor that resembles dragon scales. They protect the entrance to the Citadel, which is heavily guarded and more secure than the city gates. The Dragon Guards are also responsible for taking care of dragons, which are kept in the lower chamber of the castle.\n",
      "**************************************************\n",
      "\n",
      "\n",
      "CPU times: total: 1h 28min 13s\n",
      "Wall time: 24min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = query_engine.query(\"What is a Dragon Guard?\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "https://github.com/fithisux/local-llm-with-chromadb/blob/main/christophergs.ipynb",
     "timestamp": 1709138451254
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0003af9453b9461a966296196a65c48d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6b1bb5f074064eed9508e76ed7aa85c1",
      "max": 125,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6d9898e60250427da3a2876ae1f2f754",
      "value": 125
     }
    },
    "0198d7b8d71e40389e77b23a060def04": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "036854173d994890ac1a9e1e3ef8ab3b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b848919dae244b4998ce23575f698ca0",
      "placeholder": "​",
      "style": "IPY_MODEL_4c214d64753d4a0ab6bfd0999b7ef8e9",
      "value": "tokenizer.model: 100%"
     }
    },
    "079325b4c6c643558d583e5a1eec89b9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0908a20f70514e55bbf234dbfe459479": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0961894699e34a2b8f2007e0673ed050": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0dfff2dfb6b542e4a200675937fff40e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_53c12114c0c949d6b669470ad7f127ed",
       "IPY_MODEL_19d51f7d861f4b669ff8d955b48e45e1",
       "IPY_MODEL_d331b53eaaf542a4ba7838c903b5d747"
      ],
      "layout": "IPY_MODEL_ab6adf2409224f9bb6d6c5014a904207"
     }
    },
    "0e4d11dbcb5243059796de69fa05b278": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "19c0f5a7175e4891b93752da31961c0e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4c5ea5aab14a4721b1627d497a94148a",
      "placeholder": "​",
      "style": "IPY_MODEL_a0c881300a4746e4aaa6efd795cb8e66",
      "value": " 493k/493k [00:00&lt;00:00, 34.4MB/s]"
     }
    },
    "19d51f7d861f4b669ff8d955b48e45e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_941b79c340d241d5a7323f7161c09272",
      "max": 733,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c5eca3d8e25c42898e9108462261b067",
      "value": 733
     }
    },
    "1b0f31be2647435fbe4a464ff76f62d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e8eacde2202e43008bf8b35262b32e1f",
      "max": 493443,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3e0a63cf422a432b93dc7af1ff7cf85b",
      "value": 493443
     }
    },
    "1b9bb6444205426d9f2c1e3084d47c03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_48e9035160644613bf4ee8a6c22d4743",
      "placeholder": "​",
      "style": "IPY_MODEL_97ae325b7caa47bcb3c4784dbfb73cf9",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "1e2bf2cba46f4c49b1136a8bab67df0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1e63d24a59b04ba1a7db63a613e7a99e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cc6a49cdbea44b2ba7d2c15724828d31",
      "placeholder": "​",
      "style": "IPY_MODEL_32990c042d744ad3afae3e03eac3fe1f",
      "value": "model.safetensors: 100%"
     }
    },
    "1f42c6913eab4a618278ae877b21fd14": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e70f92cdd188498ebff8f320ac112998",
      "max": 72,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b1730ee391ec4ef9a3dd9e2e9876417a",
      "value": 72
     }
    },
    "200eb5111a5b4fa8b604b32a14f37e0e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "20977fa7019d47f6ab4e37d037999b76": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2eaba381f8b946adb9b5c89bcae78685",
      "placeholder": "​",
      "style": "IPY_MODEL_4fa422a6c52a48be88f810caba43fca1",
      "value": " 1.34G/1.34G [00:10&lt;00:00, 166MB/s]"
     }
    },
    "291a6354dc6e4698865e3d86c5ee1bb1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2d00f832a6ae4c4288a03a7e61bc2f49",
      "placeholder": "​",
      "style": "IPY_MODEL_423845aaad2d48b7b856fc60d8fc6f4f",
      "value": ""
     }
    },
    "2d00f832a6ae4c4288a03a7e61bc2f49": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2db16ed3278c4bfe8acf9202768de6b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_89dfd97749224ed3a58e8f4d6bdf5158",
      "max": 1242,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1e2bf2cba46f4c49b1136a8bab67df0a",
      "value": 1242
     }
    },
    "2e66c38f5e404ce4bbf2a0a6edba89a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_036854173d994890ac1a9e1e3ef8ab3b",
       "IPY_MODEL_1b0f31be2647435fbe4a464ff76f62d1",
       "IPY_MODEL_19c0f5a7175e4891b93752da31961c0e"
      ],
      "layout": "IPY_MODEL_d69be2c59406490e819c707500c0b9cb"
     }
    },
    "2e726638713b4af9abaf65bd35376863": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2eaba381f8b946adb9b5c89bcae78685": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "319d6139ec7d4864a18b60bef75032aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b4aa2d88328948b882e7b17764042f69",
      "placeholder": "​",
      "style": "IPY_MODEL_dff9671556f149ba9f9a9f0425e44b02",
      "value": " 1.24k/1.24k [00:00&lt;00:00, 69.6kB/s]"
     }
    },
    "32990c042d744ad3afae3e03eac3fe1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "337cc33084e44a83a5ff6ecff24b773a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_76066fc64a194d288a222fef218d1df1",
      "placeholder": "​",
      "style": "IPY_MODEL_72c30a2b48fe4b4589a14b8f03a766f9",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "394193e2ea6e47bd95c15c72cfb01b11": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_852773c444a84b0cb7bf793c9ec5be8f",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7b12d5154319457f858cdc54d09d4fe6",
      "value": 231508
     }
    },
    "3e0a63cf422a432b93dc7af1ff7cf85b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3f70af433ed14f689a6328744342b3f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "415b7764079a4f91a95d0d166487bc42": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "41808496e82a496b8a8bf897e753ee34": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ca9eb1ba34064f358b5c9dac35ad96d5",
      "placeholder": "​",
      "style": "IPY_MODEL_3f70af433ed14f689a6328744342b3f5",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "423845aaad2d48b7b856fc60d8fc6f4f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "48e9035160644613bf4ee8a6c22d4743": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b8e1ccd5af1469fad3fa2f17b1fbb6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1e63d24a59b04ba1a7db63a613e7a99e",
       "IPY_MODEL_9b1f3fcf64d4424b93dab8e108df5786",
       "IPY_MODEL_20977fa7019d47f6ab4e37d037999b76"
      ],
      "layout": "IPY_MODEL_c5a3731cc0774bcbbcc6063425146d0e"
     }
    },
    "4c214d64753d4a0ab6bfd0999b7ef8e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4c5ea5aab14a4721b1627d497a94148a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4fa422a6c52a48be88f810caba43fca1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "502040ae722842d29c64fdf5756eb8cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "50d2c55c2fb64a7e9ae727af6e2bae61": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "53c12114c0c949d6b669470ad7f127ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e344c647c7634e57b9ea3d80d3714f81",
      "placeholder": "​",
      "style": "IPY_MODEL_61b466859383483ab406fce21056538c",
      "value": "config.json: 100%"
     }
    },
    "54cd52f55628482eb6fd8acdfe08b788": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b7439fa380a3479485a72f22d6a7b074",
      "placeholder": "​",
      "style": "IPY_MODEL_90e360057d1b4f97bd0226fa0a0c6883",
      "value": "tokenizer.json: 100%"
     }
    },
    "568ebe15c3914a25a5810d1b61024560": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7ac20c42ab39447f881ba5cc364491d1",
      "max": 711396,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d8668140890b446c8cb2ed00bfd758f0",
      "value": 711396
     }
    },
    "57b85f6768b24faba97e6516d0161024": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "588df6baf97f4d89b47e384935544680": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_54cd52f55628482eb6fd8acdfe08b788",
       "IPY_MODEL_7d79784221834c1e815afe3121203674",
       "IPY_MODEL_d1a8527e05914c95917e8507900a64ca"
      ],
      "layout": "IPY_MODEL_200eb5111a5b4fa8b604b32a14f37e0e"
     }
    },
    "59776c188ba845598e081a863cab2275": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_41808496e82a496b8a8bf897e753ee34",
       "IPY_MODEL_0003af9453b9461a966296196a65c48d",
       "IPY_MODEL_b748bcb289b54f9f8b32be94b66e2242"
      ],
      "layout": "IPY_MODEL_ab53ccdc938c41fe9436f0221b2a3c0a"
     }
    },
    "5d7edaae86334f7d991de13d5b42d9a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "610c6698d8ba41f5915f5fb8f940cc14": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_415b7764079a4f91a95d0d166487bc42",
      "placeholder": "​",
      "style": "IPY_MODEL_cdc0c7eeb9cd4efa8a106c73bdda9cee",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "61b466859383483ab406fce21056538c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6b1bb5f074064eed9508e76ed7aa85c1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6cf9d2700a5041bba56802ac4f6ec72e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7af4423428384ebea388f88695fd5d50",
      "placeholder": "​",
      "style": "IPY_MODEL_a521df36522d4b549596bbc69a015221",
      "value": " 72.0/72.0 [00:00&lt;00:00, 4.80kB/s]"
     }
    },
    "6d9898e60250427da3a2876ae1f2f754": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6dfead868430481185af3dbcc5a6e7bd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "72c30a2b48fe4b4589a14b8f03a766f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "72da250867914ebb8d84c35f9cf8d9e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "76066fc64a194d288a222fef218d1df1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7ac20c42ab39447f881ba5cc364491d1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7af4423428384ebea388f88695fd5d50": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7b12d5154319457f858cdc54d09d4fe6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7d79784221834c1e815afe3121203674": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e2eaa932d419460da2c3ef4372e11908",
      "max": 1795303,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c48ad5335e6949f1b913b178f25ae0d0",
      "value": 1795303
     }
    },
    "7eb52167968e4550b7911d62e940d7a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a9e02338e37a403d89c7e454181b5d24",
       "IPY_MODEL_394193e2ea6e47bd95c15c72cfb01b11",
       "IPY_MODEL_b151f46987594085b7013dde99353200"
      ],
      "layout": "IPY_MODEL_0961894699e34a2b8f2007e0673ed050"
     }
    },
    "852773c444a84b0cb7bf793c9ec5be8f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "85c9afe57c22490c98b49ddff86b8c2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c51356f765d44349b5ba0c8bf09428f8",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5d7edaae86334f7d991de13d5b42d9a9",
      "value": 0
     }
    },
    "86c340ce56fd4778b8baba861144f72e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f88c414bbe9d45c889b45f1425eb033b",
       "IPY_MODEL_568ebe15c3914a25a5810d1b61024560",
       "IPY_MODEL_c7d73f2a4fc24f0cacf444fbca6e8167"
      ],
      "layout": "IPY_MODEL_079325b4c6c643558d583e5a1eec89b9"
     }
    },
    "89dfd97749224ed3a58e8f4d6bdf5158": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "90e360057d1b4f97bd0226fa0a0c6883": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "93978c30008b43678baa672ad1a804cf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "941b79c340d241d5a7323f7161c09272": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "97ae325b7caa47bcb3c4784dbfb73cf9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "97fc2dd9aa4c473f8f24681b09fdb14d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ee5ca0ccdae844499527ee6621b8b674",
      "max": 1460,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a4cf1767ced148e19230acddc1ee0111",
      "value": 1460
     }
    },
    "9880bec0ae7e48499c6789b024e01577": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9b1f3fcf64d4424b93dab8e108df5786": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cdebc24318424786894d1aafff286821",
      "max": 1340612432,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ea00bc805dee49b5afe998d680bf4b4e",
      "value": 1340612432
     }
    },
    "a0410383f3e84975af0126e862552c16": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a0c881300a4746e4aaa6efd795cb8e66": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a4cf1767ced148e19230acddc1ee0111": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a521df36522d4b549596bbc69a015221": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a9e02338e37a403d89c7e454181b5d24": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e59e1197b6ab4b7db539a2e140bf0140",
      "placeholder": "​",
      "style": "IPY_MODEL_9880bec0ae7e48499c6789b024e01577",
      "value": "vocab.txt: 100%"
     }
    },
    "ab53ccdc938c41fe9436f0221b2a3c0a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ab6adf2409224f9bb6d6c5014a904207": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ac9730efa73d4f319f163ea4db9cb832": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b0261842d4db444ab7e3da62ff57e63f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_337cc33084e44a83a5ff6ecff24b773a",
       "IPY_MODEL_97fc2dd9aa4c473f8f24681b09fdb14d",
       "IPY_MODEL_bea91842bf04485d8cd5fb966e576e78"
      ],
      "layout": "IPY_MODEL_c2b138dadc284228bac0ac57efeb1126"
     }
    },
    "b151f46987594085b7013dde99353200": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0e4d11dbcb5243059796de69fa05b278",
      "placeholder": "​",
      "style": "IPY_MODEL_c1b908b2648d458ab6a002a52681562d",
      "value": " 232k/232k [00:00&lt;00:00, 4.50MB/s]"
     }
    },
    "b1730ee391ec4ef9a3dd9e2e9876417a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b4aa2d88328948b882e7b17764042f69": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b7439fa380a3479485a72f22d6a7b074": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b748bcb289b54f9f8b32be94b66e2242": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ca23ad2fd52a4298bb552c868d94f491",
      "placeholder": "​",
      "style": "IPY_MODEL_57b85f6768b24faba97e6516d0161024",
      "value": " 125/125 [00:00&lt;00:00, 8.55kB/s]"
     }
    },
    "b848919dae244b4998ce23575f698ca0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bb3ca13726c2495aa3d3b3f7480b2a37": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_610c6698d8ba41f5915f5fb8f940cc14",
       "IPY_MODEL_2db16ed3278c4bfe8acf9202768de6b1",
       "IPY_MODEL_319d6139ec7d4864a18b60bef75032aa"
      ],
      "layout": "IPY_MODEL_0908a20f70514e55bbf234dbfe459479"
     }
    },
    "bea91842bf04485d8cd5fb966e576e78": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6dfead868430481185af3dbcc5a6e7bd",
      "placeholder": "​",
      "style": "IPY_MODEL_ff368e09220e4b1794d85f99e09839af",
      "value": " 1.46k/1.46k [00:00&lt;00:00, 105kB/s]"
     }
    },
    "c1b908b2648d458ab6a002a52681562d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c2b138dadc284228bac0ac57efeb1126": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c48ad5335e6949f1b913b178f25ae0d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c51356f765d44349b5ba0c8bf09428f8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "c5a3731cc0774bcbbcc6063425146d0e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5eca3d8e25c42898e9108462261b067": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c7d73f2a4fc24f0cacf444fbca6e8167": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_93978c30008b43678baa672ad1a804cf",
      "placeholder": "​",
      "style": "IPY_MODEL_72da250867914ebb8d84c35f9cf8d9e2",
      "value": " 711k/711k [00:00&lt;00:00, 27.4MB/s]"
     }
    },
    "ca23ad2fd52a4298bb552c868d94f491": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca9eb1ba34064f358b5c9dac35ad96d5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cc6a49cdbea44b2ba7d2c15724828d31": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ccc1f56170bf457cab2d20bb58377bc4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1b9bb6444205426d9f2c1e3084d47c03",
       "IPY_MODEL_1f42c6913eab4a618278ae877b21fd14",
       "IPY_MODEL_6cf9d2700a5041bba56802ac4f6ec72e"
      ],
      "layout": "IPY_MODEL_eb06dd2d906d46cc890a87555cfe334d"
     }
    },
    "cdc0c7eeb9cd4efa8a106c73bdda9cee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cdebc24318424786894d1aafff286821": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d1a8527e05914c95917e8507900a64ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d59b58dc490f480493238b0badd9f22d",
      "placeholder": "​",
      "style": "IPY_MODEL_2e726638713b4af9abaf65bd35376863",
      "value": " 1.80M/1.80M [00:00&lt;00:00, 36.9MB/s]"
     }
    },
    "d331b53eaaf542a4ba7838c903b5d747": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0198d7b8d71e40389e77b23a060def04",
      "placeholder": "​",
      "style": "IPY_MODEL_f65488d28f1d4499a19aa715a6807bfd",
      "value": " 733/733 [00:00&lt;00:00, 36.5kB/s]"
     }
    },
    "d59b58dc490f480493238b0badd9f22d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d69be2c59406490e819c707500c0b9cb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d8668140890b446c8cb2ed00bfd758f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d87b40175e364504aedf2e38a594fbae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_50d2c55c2fb64a7e9ae727af6e2bae61",
      "placeholder": "​",
      "style": "IPY_MODEL_502040ae722842d29c64fdf5756eb8cb",
      "value": " 0/0 [00:00&lt;?, ?it/s]"
     }
    },
    "df5c051dafd64e80865173434a61ffc8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_291a6354dc6e4698865e3d86c5ee1bb1",
       "IPY_MODEL_85c9afe57c22490c98b49ddff86b8c2c",
       "IPY_MODEL_d87b40175e364504aedf2e38a594fbae"
      ],
      "layout": "IPY_MODEL_eb3a2814a8f4480480dd1c8892b4a72d"
     }
    },
    "dff9671556f149ba9f9a9f0425e44b02": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e2eaa932d419460da2c3ef4372e11908": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e344c647c7634e57b9ea3d80d3714f81": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e59e1197b6ab4b7db539a2e140bf0140": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e70f92cdd188498ebff8f320ac112998": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e8eacde2202e43008bf8b35262b32e1f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea00bc805dee49b5afe998d680bf4b4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "eb06dd2d906d46cc890a87555cfe334d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eb3a2814a8f4480480dd1c8892b4a72d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ee5ca0ccdae844499527ee6621b8b674": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f65488d28f1d4499a19aa715a6807bfd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f88c414bbe9d45c889b45f1425eb033b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0410383f3e84975af0126e862552c16",
      "placeholder": "​",
      "style": "IPY_MODEL_ac9730efa73d4f319f163ea4db9cb832",
      "value": "tokenizer.json: 100%"
     }
    },
    "ff368e09220e4b1794d85f99e09839af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
